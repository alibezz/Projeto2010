Get out the vote: Determining support or opposition from Congressional floor-debate transcripts

Proposta: ver orientação de discursos contra ou a favor duma legislação. Isso num debate.

TEM UMA FRASE MAAAARAAAA NO COMEÇO! No caso de política, as pessoas se sentem naturalmente mais interessada em ler textos opinionados do que as leis em discussão, por exemplo, pela seu léxico mto particular e pelo tamanho dos documentos.

Agreement: se, dentro dum texto, vc encontra mto agreement com um claramente positivo, isso pode ajudar a classificá-lo como positivo tb. => segundo o artigo, só traz beneficio se os artigos são dificeis de classificar individualmente. Parece ser o caso dos dados tratados, onde há digressões, mtos tópicos e um léxico mto vasto (dispersão). O approach tb vai numa linha inter-documentos.

=> O artigo incorpora agreement e compara com SVMs (estado da arte no momento) => DIVERGÊNCIA ENTRE O QUE SE DIZ ESTADO DA ARTE COM O LSPM OU NA VERDADE SÃO PROBLEMAS DIFERENTES PQ UM EH ARTIGO E OUTRO É DEBATE?

Pegaram debates em que pelo menos 20% dos speeches provinham do lado que havia perdido. Classifica um segmento de fala de cada pessoa.

Bacana é que eles partem os dados RANDOMICAMENTE entre training, testing e development - certamente pra n correlacionar as coisas.

Modelagem: seja s um segment speech e Y a classe pŕo e N a contra. Existe ma função ind(s,C) que indica o grau de preferência para pôr s em C. Além disso, alguns pares de speech segments si,sj podem ter weighted links entre eles, str(l), indicando o grau to which it is preferable that the linked speech segments receive the same label.

Aí vc tem um custo pra c = c(s1),c(s2)... que é somatório dos ind(s, notC) + somatorio de str(l) para pares s,s', onde l é o link entre s,s' e c(s) != c(s'). Aí vc vai pro minimum cost assignment, com highly associated speech segments tending not to be put in different classes. => Dá pra resolver usando minimum cuts in graphs.


===> Por mais que a galera mude de opinião no debate, o fato de dois segment speeches serem escritos pelo mesmo autor já faz com que surja um link a ser weighted aí.

===> Autores diferentes: como achar agreement? identificar referências and their targets e decidir se essas referencias são instancias de agreement. As unicas referencias usadas são nomes dos outros speakers, daí o primeiro problema é resolvido trivialmente. Pra ver se rola agreement, ela pega uma janela de texto surrounding a referência e compõe um word-presence vector. Daí, classifica a reference conectando os dois speakers como positiva ou negativa a depender deles terem ou n votado da mesma forma na bill under discussion (training set). Esses labels treinam um SVM classifier e o output serve pra criar os weights dos agreement links no test set. 


Na parte dos agreement links, uma coisa a se observar é: falsos positivos podem fazer textos de labels diferentes serem assigned da mesma forma; falsos negativos apenas indicam que a informação de agreement sobre outros speech segments não foi empregada.

Depois, ele para de usar as unidades como speech segments e passa a usar tudo que um speaker fala, meso. Ou seja, quer considerar relações **entre** speakers. A classificação por speaker funciona melhor que por speech segment, como era de se esperar.


===> Esse artigo é relativamente fácil de adaptar pra português
