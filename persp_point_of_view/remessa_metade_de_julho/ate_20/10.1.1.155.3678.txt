Labeled LDA: A supervised topic model for credit attribution in multi-labeled corpora

O labeled LDA cria correspondência um-para-um entre os tópicos latentes do LDA e tags de usuário (coisa linda, mamãe!).

Mote: boa parte dos textos na web são labeled com tags. Entretanto, nem todas as tags se aplicam com igual especificidade através do documento inteio. => Pode ser que, num IR da vida, qdo vc busca por uma tag vc pode querer ver o texto ali marcado com uma cor diferente.

O LDA puro às vezes gera tópicos mto complicados de interpretar!

Com labels têm significado pras pessoas que as colocam, vale mais assign document's words aos labels do que a um "latent and possibly less interpretable semantic space".

Sensacional pra blogs e twitter! Cada label É um tópico! Como no LDA, o LLDA modela cada documento como uma mistura de underlying topics and generates.

Seja cada documento d uma tupla wd = (w1, ..., wNd) e uma lista de tópicos binários X = (l1, ..., lk). O número de tópicos no LLDA é K.

VER ALGORITMO NO ARTIGO

Seja K = 4 e um documento d tem Xd = {0,1,1,0}, ou seja, lambda_d = {2,3}. Entãao, Ld  é 0 1 0 0 .
              0 0 1 0

Aí, a multinomial mixture distribution theta_d over all K topics fica

theta_d = (theta_l1, ..., theta_lMd) ~ Dir(.|alpha_d), onde Md = n. de topicos presentes = 2 e alpha_d = Ld * (alpha_1, ..., alpha_K) = (alpha_2, alpha3)T => OU SEJA, OS TOPICOS DO DOCUMENTO SÃO SUAS PROPRIAS TAGS!

Legal para fazer uma avaliação granular da coisa.



Relação com Naive Bayes: Apesar de gerar probabilidades como um multinomial naive bayes classifier no caso em q cada documento tem apenas um label, nunca faz nada do tipo P(wd|ld) versus P(wd|~ld).

It helps summarizing information!


=> Experimento: escolheu 20 tas com média/alta frequencia no del.icio.us. filtrou por tags uns 4000 documentos q continham pelo menos uma delas, retirando aquelas tags q tavam fora do movimento, tirou as stop-words e chegou à media de umas 4 tags por documento (VERY MULTIPLY LABELED).

Dá pra extrair snippets que de fato sejam relevantes pra tag melhor que com svm. dá pra, dado um conjunto de treinamento com documentos e seus multiplos labels, prever os labels apropriados para cada documento em um test set.

O LLDA se sai melhor que o SVM nessa text classification talvez por modelar explicitamente a importância das tags nos documentos! Além disso, pela estrutura do LLDA, ele naturalmente faz um certo word-sense disambiguation.


Muito estudo pode rolar ainda. Dede ver correlação entre tags até adaptar pra corpora onde apenas alguns textos foram tagged.
