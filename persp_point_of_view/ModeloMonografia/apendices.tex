\appendix

\chapter{Teorema de Bayes e notações}

A Estatística se alia à Teoria da Probabilidade para estimar e analisar a ocorrência de eventos, como \emph{Ganho de cem reais em sorteio} ou \emph{Chuva ao meio-dia}. Dados dois eventos \emph{A} e \emph{B}, temos que a probabilidade \emph{a priori} de \emph{A} acontecer \textbf{ignora} a ocorrência do evento \emph{B}. Essa probabilidade é representada pela notação \ensuremath{P(A)} \cite{spiegelhalter}. Analogamente, para o evento \emph{B}, tem-se \ensuremath{P(B)}. Na prática sabe-se, intuitivamente, que a ocorrência de determinados eventos interfere no acontecimento de outros. Se às onze e meia da manhã observa-se o evento \emph{Céu nublado}, a probabilidade do evento \emph{Chuva ao meio-dia} ocorrer pode diferir daquela que ignora esse primeiro evento. Neste sentido, a probabilidade de um evento \emph{A} ocorrer \emph{dado} que \emph{B} ocorreu recebe o nome de probabilidade condicional de \emph{A} dado \emph{B}, e é denotada por \ensuremath{P(A\mbox{ }|\mbox{ }B)} \cite{spiegelhalter}. Analogamente, tem-se \ensuremath{P(B\mbox{ }|\mbox{ }A)}. O Teorema de Bayes correlaciona essas probabilidades da seguinte forma \cite{spiegelhalter}

\begin{equation}
\label{bayes-apendice}
\ensuremath{P(A\mbox{ }|\mbox{ }B) = \frac{P(B\mbox{ }|\mbox{ }A)P(A)}{P(B)}} 
\end{equation}

No contexto da Equação \ref{bayes-apendice}, \ensuremath{P(A\mbox{ }|\mbox{ }B)} recebe o nome de probabilidade \emph{a posteriori} de \emph{A} e \ensuremath{P(B\mbox{ }|\mbox{ }A)} recebe o nome de \emph{likelihood} \cite{spiegelhalter}. O classificador Naïve Bayes se baseia em uma aplicação direta do Teorema de Bayes.  Dados os eventos \emph{Obtenção de um documento x} e \emph{Obtenção de uma classe y}, o classificador deve estimar a ocorrência do segundo evento assumindo que o primeiro já ocorreu.   

\chapter{Código do Naïve Bayes}

A implementação do Naïve Bayes foi feita em Python, aplicando o algoritmo de inferência Gibbs Sampling para estimar parâmetros e classes. Há uma classe responsável pelo \emph{parsing} dos documentos, \textbf{CorpusParser}, e outra para o classificador em si, \textbf{NaiveBayesSampler}.

\section{CorpusParser}

\begin{lstlisting}

#Aline Bessa - 17/05/2010
import sys
import os
import numpy as np
import random
from nltk import *

stop_words = [] 

def read_file(file):
   text = []
   line = file.readline()
   while(line != ""):
     text.append(str(line).strip())
     line = file.readline()
   return text

def get_words(text):
  import re
  wre = re.compile(r"(\w)+")
  l = 0
  while l < len(text):
       s = wre.search(text,l)
       try:
           yield text[s.start():s.end()]
           l = s.end()
       except:
           break

class CorpusParser(object):
  def __init__(self, train_corpus, test_corpus):
    self.train_corpus = train_corpus
    self.Ntrain_corpus = len(os.listdir(train_corpus))
    self.test_corpus = test_corpus
    self.Ntest_corpus = len(os.listdir(test_corpus))
    self.train_list_docs = os.listdir(train_corpus)
    self.test_list_docs = os.listdir(test_corpus)
    self.train_docs = []
    self.test_docs = []

    self.all_words = []

  def train_dirname(self):
    return self.train_corpus
  def test_dirname(self):
    return self.test_corpus

  def chop(self, raw_sntc):
    x = raw_sntc.find(">") + 1
    y = raw_sntc.find("</")
    return raw_sntc[x:y]

  def words(self):
    return self.all_words

  def get_new_words(self, doc):
    for i in xrange(len(doc)):
      for t in get_words(str(doc[i])):
        t = t.lower().strip()
       # t = en.noun.singular(t)
        if not t in self.all_words and not t in stop_words:
          self.all_words.append(t)

  def ldocs(self):
    return self.list_docs

  def dirname(self):
    return self.corpus

  def get_doc(self, doc):
    counts = np.zeros(len(self.all_words))
    for sntc in doc:
      for t in get_words(sntc):
        t = t.lower().strip()
       # t = en.noun.singular(t)
        if not t in stop_words and t in self.all_words:
          counts[self.all_words.index(t)] += 1.
    return counts

  #TODO cut redundancy between docs and dir params
  def iterate_corpus(self, docs, dir, action, 
                     doc_preprocessing = None):
    for file in docs:
      f = open(os.path.realpath(dir + '/' + file), 'r')
      doc = read_file(f)
      if doc_preprocessing:
        action(doc_preprocessing(doc))
      else:
        action(doc)
      f.close()


  ###get every single word first
  def pdocs(self):

    self.iterate_corpus(self.train_list_docs, self.train_corpus, 
                        self.get_new_words)
    self.iterate_corpus(self.test_list_docs, self.test_corpus, 
                        self.get_new_words)
    self.iterate_corpus(self.train_list_docs, self.train_corpus, 
                        self.train_docs.append, self.get_doc)
    self.iterate_corpus(self.test_list_docs, self.test_corpus, 
                        self.test_docs.append, self.get_doc)
    return self.train_docs, self.test_docs
 # print self.all_words, len(self.all_words)

if __name__ =='__main__':
  a = CorpusParser(sys.argv[1], sys.argv[2])
  a.pdocs()


\end{lstlisting}

\section{NaiveBayesSampler}

\begin{lstlisting}

#Aline Bessa - 27/04/2010
#Naive Bayes modelling for sentiment analysis in docs

import numpy as np
import random
import math
from parse_nb import CorpusParser
import sys
import os

class NaiveBayesSampler(object):
  def __init__(self, a):
    pdocs = a.pdocs()
    self.train_docs = pdocs[0]
    self.test_docs = pdocs[1]
    self.docs = self.train_docs + self.test_docs

    if not self.docs: 
      self.all_words = 0
    else:
      self.all_words = len(self.docs[0])
    #print self.all_words
    self.train_dirname = a.train_dirname()
    self.test_dirname = a.test_dirname()
    self.labels = [] 
    self.Ntraindocs = len(self.train_docs)
    self.Ntestdocs = len(self.test_docs)

  def initial_label(self):
    return np.random.binomial(1, self.pi)

  def get_real_label(self, dir, index):
    #assumptions, assumptions: sit = 1; opos = 0
    ldocs = os.listdir(dir)
    if ldocs[index].find("opos") >= 0:
      return 0
    else:
      return 1

  def label_documents(self):
    for i in xrange(self.Ntraindocs):
      label = self.get_real_label(self.train_dirname, i)
      self.labels.append(label)
    for i in xrange(self.Ntestdocs):
      label = self.initial_label()
      self.labels.append(label)

  def pLi(self, j, doc):
    #This is how the probabilities are 
    #ACTUALLY calculated (Gibbs Sampling)   
    # Log - implementation detail: it smoothes the computations
    t1 = np.log((self.dccs[j] + self.Gammapi[j])/
        (len(self.labels) + self.Gammapi[1] + self.Gammapi[0] -1))
    t2 = doc*np.log(self.theta[j])
    t2 = np.sum(t2)
    return t1+t2


  def pick_label(self, j):
    lclass = self.labels[j]
    self.dccs[lclass] -= 1 
    self.wccs[lclass] -= self.docs[j] 

    pL0 = self.pLi(0, self.docs[j]) 
    pL1 = self.pLi(1, self.docs[j])
    loglr = pL1-pL0
    lr = np.exp(loglr)
    if lr == np.inf:
      label = 1
    else:
      if np.random.binomial(1, lr/(1+lr)):
        label = 1
      else:
        label = 0
    self.labels[j] = label
    self.dccs[label] += 1
    self.wccs[label] += self.docs[j]
    return label
  
  def get_denominator(self):
      den = np.zeros(2)
      for i in range(self.Ntestdocs):
        den[self.get_real_label(self.test_dirname, i)] += 1
      return den

  def num_den(self):
    den = self.get_denominator()
    num = np.zeros(2)
    
    for i in range(self.Ntestdocs):
      #shifting Ntraindocs positions
      l = self.labels[i + self.Ntraindocs] 
      if l == self.get_real_label(self.test_dirname, i):
        num[self.labels[i + self.Ntraindocs]] += 1
    
    return num, den 

  def precision(self, num, den):
    #TP/(TP+FP)
    return num[0]/(num[0] + (den[1] - num[1])), 
           num[1]/(num[1] + (den[0] - num[0]))

  def accuracy(self, num, den):
    return num[0]/den[0], num[1]/den[1], 
          (num[0] + num[1])/(den[0] + den[1])
 
  def sample(self, nsamples):
    self.Gammapi = np.array([1., 1.])
    self.Gammatheta = np.array([1. for i in xrange(self.all_words)])
    self.pi = random.betavariate(1,1)
    self.theta = np.zeros((2, self.all_words)) 
    self.theta[0] = np.random.dirichlet(self.Gammatheta) 
    self.theta[1] = np.random.dirichlet(self.Gammatheta) 
    self.label_documents()
    self.wccs = np.zeros((2, self.all_words))
    self.dccs = np.zeros(2)

    for i, a in enumerate(self.labels):
      self.dccs[a] += 1
      self.wccs[a] += self.docs[i]

    for i in xrange(nsamples):
      for j in xrange(self.Ntestdocs):
        #shifting Ntraindocs positions
        self.pick_label(j + self.Ntraindocs) 
      self.theta[0] =
      np.random.dirichlet(self.Gammatheta + self.wccs[0])
      self.theta[1] = 
      np.random.dirichlet(self.Gammatheta + self.wccs[1])

      num, den = self.num_den()
      print num[0], num[1]
      print den[0], den[1]
      print "accuracy"
      ac = self.accuracy(num, den)
      print ac
      print "precision"
      pr = self.precision(num, den)
      print pr
      print "f1 measure"
      print 2*pr[0]*ac[0]/(pr[0] + ac[0]), 
            2*pr[1]*ac[1]/(pr[1] + ac[1]) 

if __name__=='__main__':
  a = CorpusParser(sys.argv[1], sys.argv[2]) 
  s = NaiveBayesSampler(a)
  s.sample(500)

\end{lstlisting}
