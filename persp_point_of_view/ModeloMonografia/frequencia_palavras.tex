\chapter{Classificação de acordo com pontos de vista: revisão e discussão}
\label{chap3}

A classificação de documentos de acordo com seus pontos de vista é um tópico de pesquisa relativamente novo. Ele foi proposto como subproblema da área de Mineração de Opinião em 2008, pelas pesquisadoras Bo Pang e Lillian Lee \cite{omsa}. De acordo com elas, esse subproblema se diferencia da classificação por opinião por não configurar as classes como pólos (\emph{positivo}, \emph{negativo} etc.). De fato, a classificação por ponto de vista visa a separar os documentos de um corpus de acordo com seus diferentes posicionamentos sobre um tema, como \emph{pró-Israel} ou \emph{pró-Palestina}. Um bom exemplo da diferença entre um ponto de vista e uma opinião, no contexto dos trabalhos revisados e de acordo com a \emph{survey} de Pang e Lee, é o seguinte: \emph{'Matrix' é um filme excelente} (opinião sobre um objeto específico, mais pontual) e \emph{a paz mundial dificilmente será alcançada} (ponto de vista sobre um tema). %Apesar de ter sido proposto formalmente apenas em 2008, uma conferência importante para a área de Mineração de Opinião, a \emph{AAAI  Conference}\footnote{\emph{Association for the Advancement of Artificial Intelligence Conference}.}, lançou, na edição de 2010, uma seção específica para trabalhos nesta direção: \emph{Sentiment and Perspective}. Isso indica que o subproblema deve se fortalecer como área de pesquisa nos próximos anos.

A \emph{survey} de Pang e Lee, uma das principais referências para este projeto, apresenta superficialmente alguns trabalhos que fazem classificação de acordo com pontos de vista, na seção em que discute o tema. Todos eles foram publicados entre os anos de 2004 e 2006. Assim como nessa \emph{survey}, esta monografia também explora trabalhos recentes: todos eles foram publicados entre 2006 e 2010. A metodologia aplicada na busca por trabalhos a serem revisados foi a seguinte: % pode ser resumida nos seguintes passos:

\begin{enumerate}
\item Consideração dos trabalhos indicados na \emph{survey} de Pang e Lee;
\item Busca, no \emph{Google Scholar}, por trabalhos citados nesses artigos;
\item Busca, no \emph{Google Scholar}, por trabalhos que citam os artigos coletados nos itens anteriores;
\item Busca, na \emph{ACL Anthology}\footnote{A \emph{Association of Computational Linguistics}, \emph{ACL}, mantém o maior arquivo digital envolvendo trabalhos de Linguística Computacional, o que inclui Mineração de Opinião (http://aclweb.org/anthology-new/).} pelas palavras \emph{perspective}, \emph{viewpoint}, \emph{politics}, \emph{political}, \emph{ideology} e \emph{ideological}. Estas palavras foram escolhidas por (1) funcionarem como sinônimos nos artigos coletados anteriormente ou (2) pela relevância em suas temáticas;
\item Busca nos \emph{sites} dos eventos \emph{EMNLP\footnote{\emph{Empirical Methods in Natural Language Processing Conference.}}, NAACL\footnote{\emph{North American Chapter of the Association for Computational Linguistics Conference.}}, AAAI\footnote{\emph{Association for the Advancement of Artificial Intelligence Conference.}}} e \emph{CoNNL\footnote{\emph{Computational Natural Language Learning Conference.}}}, realizados entre 2000 e 2010, pelas mesmas palavras do item anterior. Esses eventos foram selecionados pela relevância na área de Mineração de Opinião. 
\end{enumerate}

Nem todos os trabalhos coletados, de acordo com essa metodologia, tinham necessariamente a ver com classificação de acordo com pontos de vista. Alguns, como a tese de Alice Oh, se propõem a modelar computacionalmente o conceito de perspectiva \cite{alice-oh}; outros, como o artigo de Laver et al., se propõem a criar uma escala ideológica e comparar documentos de acordo com ela \cite{wordscores}.  Por este motivo, foi feita uma filtragem que resultou em onze trabalhos a serem revisados. 

Todos esses trabalhos apresentam uma metodologia em comum: eles organizam um corpus de documentos, definem em que pontos de vista ele se divide, possivelmente pré-processam os documentos e, em seguida, classificam-nos utilizando alguma técnica - na maioria dos casos, SVMs ou Naïve Bayes\footnote{Esses classificadores são apresentados no Capítulo \ref{basicos}.}. Independentemente da forma de classificação, tem-se que elas sempre se baseiam em características dos documentos para determinar suas classes. Quase todos os trabalhos revisados nesse capítulo exploram, como características,  contagens de palavras ou alguma variação delas\footnote{O conceito de contagens de palavras é apresentado no Capítulo \ref{basicos}.}. Boa parte deles não faz uso de nenhuma outra característica e alguns trabalhos as comparam com outras, que normalmente são seu enfoque. Essas outras características são escolhidas de forma muito particular, variando de um trabalho para outro. Em vez de apenas considerarem ocorrências de palavras em textos, esses trabalhos exploram suas relações sintáticas, suas propriedades semânticas e também valores associados às interações entre dois ou mais documentos. 

Dado que essas últimas características variam bastante, e considerando também a popularidade das primeiras nos trabalhos estudados, decidiu-se dividir a revisão dos trabalhos nas seguintes seções: a seção \ref{contagem} apresenta trabalhos que classificam documentos baseando-se exclusivamente em contagens de palavras ou variações - ou seja, eles desconsideram \emph{quaisquer} aspectos gramaticais dos documentos. A seção \ref{sintaxe} apresenta trabalhos que exploram outras características dos documentos na classificação. É importante informar que alguns trabalhos da segunda seção, por questões comparativas, também classificam documentos exclusivamente de acordo com contagens de palavras ou variações - mas este não é o foco deles.  Por fim, na seção \ref{compara}, é apresentada uma pequena análise comparativa envolvendo os trabalhos revisados nas seções anteriores.

%Na seção \ref{freqs:revisao}, essa revisão é apresentada. 

%Boa parte dos trabalhos revisados na seção anterior  
%Uma parte significativa dos trabalhos apresentados na seção \ref{freqs:revisao} classifica documentos explorando apenas suas diferentes contagens de palavras\footnote{É válido reforçar que, conforme apresentado no Capítulo \ref{basicos}, tem-se que, dado um documento, a contagem de uma palavra é o \emph{número de vezes} que ela ocorre nele \cite{mccallum-nigam}. Ainda nesse capítulo, as descrições dos SVMs e do Naïve Bayes evidenciam como esses classificadores podem explorar essas contagens.}. De todo modo, em alguns trabalhos, os autores propõem o emprego de outras características, mas não há sequer dois deles que as explorem da mesma forma. Neste sentido, no momento, o uso de contagens de palavras parece ser a escolha mais comum para classificação por ponto de vista.  Diante da popularidade do uso de contagens de palavras na seção \ref{freqs:revisao}, foi julgado importante, em um capítulo que discute classificação por ponto de vista, dar um enfoque especial a elas. Neste sentido, a seção \ref{freqs:experim} discute a classificação baseada em contagens de palavras, analisando a relação entre seu desempenho e o emprego de palavras por diferentes perspectivas sobre um mesmo tema.  

%\footnote{Esse conceito pode ser estendido para uma classe fixada. Neste cenário, a contagem de uma palavra é o número de vezes que ela ocorre em todos os documentos dessa classe.}

% Como apresentado no Capítulo Essas características refletem, de forma quantitativa, a hipótese de que indíviduos com posicionamentos diferentes se expressam de formas distintas, dando ênfase a palavras diferentes. Essa hipótese, é importante frisar, encontra respaldo na área de Linguística \cite{teubert}. 

% 
%Uma variação das contagen, que reflete diferentes escolhas de palavras, é a ausência/presença de palavras. Ela também foi explorada nos trabalhos revisados, mas menos do que as contagens.  

%Grande parte dos trabalhos revisados na seção \ref{freqs:revisao} exploram contagens de palavras, ou pequenas variações sobre elas, na classificação. Uma variação que recebe certo destaque são as ausências/presenças de palavras. Conforme discutido no Capítulo \ref{basicos}, tem-se que, dado um documento, a ausência/presença de uma palavra corresponde a um \emph{bit}, indicando se ela está ausente (0) ou presente (1) nele \cite{mccallum-nigam}. De todas as características exploradas na revisão, essas são as mais fáceis de computar, pois desprezam qualquer aspecto gramatical dos documentos e ignoram suas relações com outros textos. O fato de independerem de propriedades sintáticas ou semânticas faz das contagens, e de suas variações, características fáceis de serem exploradas em documentos escritos em qualquer língua. Diante desses fatores, 


%\section{Trabalhos Revisados}
%\label{freqs:revisao}


\section{Trabalhos que exploram contagens de palavras ou variações}
\label{contagem}

Esta seção apresenta seis trabalhos que classificam documentos baseando-se apenas na contagem de suas palavras ou em pequenas variações, como ausência/presença de palavras. Eles assumem, ainda que implicitamente, que os pontos de vista dos documentos já são suficientemente discrimináveis no nível das escolhas de palavras. A ênfase em palavras diferentes, ou até mesmo o uso de palavras específicas, é um elemento chave para a transmissão de posicionamentos distintos sobre um determinado assunto. Essa ideia, é válido ressaltar, encontra respaldo na área de Linguística: indivíduos com posicionamentos diferentes utilizam palavras distintas, ou as enfatizam de modos diversos, para identificar mais facilmente quem pensa da mesma forma e quem se opõe ideologicamente \cite{teubert}. %Na prática, usos diferentes de palavras podem ser comparados através de suas contagens.

O trabalho de \textbf{Lin et al.} classifica artigos do \emph{site} Bitterlemons\footnote{http://bitterlemons.org/} como pró-Palestina ou pró-Israel \cite{lin-et-al2006}. Inicialmente, os documentos são representados como listas de palavras reduzidas a seus radicais. Isso significa, por exemplo, que as palavras \emph{political} e \emph{politics} são representadas através de um mesmo termo, o radical \emph{politic}. Os classificadores Naïve Bayes e SVM são então aplicados, explorando as contagens desses radicais em cada documento. A taxa de acerto obtida com o SVM variou entre 81.48\% e 97.24\%; com o Naïve Bayes, ela variou entre 84.85\% e 99.09\%. Essas variações vêm de diferentes divisões entre os conjuntos de treinamento e teste. Em alguns casos, foi utilizada a validação cruzada \emph{10-fold}\footnote{Essa técnica de validação é descrita no Capítulo \ref{basicos}.}; em outros, os conjuntos foram divididos de acordo com os autores dos artigos. 

Por fim, o trabalho de Lin et al. propõe o classificador \emph{Latent Sentence Perspective Model}, ou simplesmente LSPM. Ele consiste em uma variação do Naïve Bayes que, em vez de considerar documentos como listas de palavras, os representa como listas de sentenças. A hipótese assumida por ele é a seguinte: nem todas as sentenças carregam um ponto de vista, de modo que o classificador, antes de definir a classe de um documento, deve selecionar quais delas carregam palavras relevantes. A taxa de acerto obtida com o LSPM variou entre  86.99\% e 94.93\%, também como consequência de diferentes divisões entre os conjuntos de treinamento e teste. Para essas divisões, as taxas de acerto obtidas com o Naïve Bayes foram de 84.85\% e 93.46\% respectivamente. O SVM não foi comparado diretamente com o LSPM. Apesar do desempenho superior ao do Naïve Bayes, nenhum outro trabalho revisado faz uso desse classificador. O tutorial de Resnik e Hardisty sobre Naïve Bayes e LSPM sugere algumas equações para a implementação deste último \cite{resnik}, mas a autora dessa monografia não foi capaz de reproduzir esses resultados. Isso foi corroborado por \cite{email}. O LSPM, que utiliza hiperparâmetros\footnote{Ver definição no Capítulo \ref{basicos}, seção \ref{subsection:naive}.} assim como o Naïve Bayes, aparenta ser muito sensível aos valores fixados.

\textbf{Mullen e Malouf} propõem dois trabalhos que analisam um conjunto de \emph{posts} do fórum de discussão política Politics\footnote{http://politics.com}. No primeiro trabalho, eles tratam cada documento como a união de todos os \emph{posts} de um mesmo usuário \cite{aaai-politics}. Cada documento é representado como uma lista de palavras, e um Naïve Bayes é aplicado considerando suas contagens em cada documento. A taxa de acerto obtida foi de 60.37\%, via validação cruzada \emph{10-fold}. O tamanho do \emph{dataset} (apenas 185 documentos) e o uso parecido de palavras por ambas as ideologias foram apontados como alguns dos principais motivos para a obtenção desse resultado.

Mullen e Malouf também sugerem que a presença de documentos menores, correspondentes a usuários do fórum que raramente postam, pode contribuir negativamente para o desempenho do Naïve Bayes. Uma última observação desse trabalho indica o que pode estar acontecendo: usuários liberais citam falas de usuários conservadores em 62.2\% de seus \emph{posts}; analogamente, conservadores citam liberais em 77.5\%  de seus \emph{posts}. A presença das perspectivas liberal e conservadora em um mesmo documento, com uma correspondendo às intenções do usuário e outra sendo citada, pode homogeneizar o uso de palavras no corpus, comprometendo a viabilidade da classificação.

%A ideia é que, como esses usuários participam muito pouco do fórum, as palavras em seus \emph{posts} não são suficientes para se consolidar uma perspectiva, tornando-os mais difíceis de se classificar. Restringindo a classificação a usuários que postaram no fórum pelo menos 20 vezes, a taxa de acerto obtida com o Naïve Bayes foi ligeiramente superior (61.38\%).  Embora o artigo não indique a proporção média entre essas citações e o restante dos documentos, é possível que elas estejam interferindo negativamente no aprendizado das perspectivas. 

%Os documentos devem ser classificados, portanto, como alinhados com uma dessas duas ideologias. , escrito por cidadãos comuns dos Estados Unidos \cite{aaai-politics} \cite{malouf-taking_sides}. Em ambos, apesar de admitirem a diversidade de posicionamentos contidos no fórum, os autores dividem os documentos em apenas duas perspectivas, por uma questão de simplicidade: liberal e conservadora.

Essa forma de interação entre os participantes do fórum é explorada pelo segundo trabalho de Mullen e Malouf \cite{malouf-taking_sides}, com o intuito de melhorar a classificação. Para isto, cria-se um grafo de co-citação em que cada vértice representa um participante e cada citação de uma fala a outra é indicada por uma aresta entre seus autores. Os participantes são agrupados de acordo com seus padrões de citação e, em seguida, as falas de cada grupo obtido são tratadas como um único documento. Aplica-se um Naïve Bayes a esta nova coleção de documentos, também explorando apenas suas contagens de palavras, e os resultados obtidos são propagados para todos os participantes de cada grupo. Essa metodologia atinge resultados significativamente melhores do que aqueles obtidos no trabalho anterior: para participantes com mais de 500 palavras de fala no fórum, a taxa de acerto relatada é de 73.00\%, via validação cruzada \emph{5-fold}. É válido salientar que, muito provavelmente, o sucesso dessa técnica é consequência do fato de que usuários alinhados ideologicamente não se citam muito. Se, além de citar seus oponentes, eles também se citassem bastante, os padrões de citação seriam sempre muito parecidos, inviabilizando os agrupamentos adequados no grafo.

O trabalho de \textbf{Durant e Smith} constrói um corpus sobre os posicionamentos do ex-Presidente George W. Bush quanto à Guerra do Iraque \cite{durant-smith}. O objetivo desse trabalho é classificar \emph{posts} de diversos \emph{blogs} políticos de acordo com os pontos de vista pró Guerra do Iraque e anti Guerra do Iraque.  Os classificadores Naïve Bayes e SVM foram aplicados, considerando apenas a ausência/presença de palavras nos documentos (uma variação das contagens de palavras). A taxa de acerto obtida com um SVM foi de 75.47\%. Com o Naïve Bayes, ela foi de 78.06\%. 

Os autores, em seguida, investigam se a seleção de apenas parte das palavras pode melhorar a classificação. Eles aplicam uma técnica denominada \emph{CfsSubsetEval}, disponível na ferramenta WEKA 3.4\footnote{http://www.cs.waikato.ac.nz/ml/weka/}, que busca um subconjunto de palavras que maximize a taxa de acerto obtida. As palavras devem ter alta correlação com as classes escolhidas, mas baixa correlação entre si. Aplicando os classificadores SVM e Naïve Bayes, e considerando apenas os subconjuntos selecionados pela técnica, as taxas de acerto obtidas foram de 87.66\% e 89.77\%, respectivamente. Todos os resultados apresentados foram obtidos via validação cruzada \emph{10-fold}. É válido ressaltar que a técnica \emph{CfsSubsetEval} pode trazer uma melhoria de desempenho significativa para \emph{datasets} escritos em qualquer língua.

O trabalho de \textbf{Hirst, Riabinin e Graham} constrói dois \emph{datasets}, um em inglês e outro em francês, que consistem de discursos de congressistas canadenses nas reuniões parlamentares \cite{hirst-et-al}. Além de classificar esses discursos como liberais ou conservadores, esse trabalho investiga se as classes correspondem de fato a ideologias diferentes ou, simplesmente, a expressões de ataque e defesa. Inicialmente, os autores analisam o \ensuremath{36^o} parlamento canadense, período em que um partido liberal estava com a maioria no poder. Excluindo apenas as palavras menos frequentes do corpus, e aplicando um SVM baseado apenas nas contagens de palavras dos documentos, as taxas de acerto obtidas foram de 83.8\% e 75.5\% para os corpora inglês e francês, respectivamente. Em seguida, os autores selecionaram o \ensuremath{39^o} Parlamento, período em que os partidos liberais eram oposição, para verificar o que de fato estava determinando a classificação. Treinando com documentos do \ensuremath{36^o} Parlamento e testando com aqueles do \ensuremath{39^o}, a classificação entre liberal e conservador é insatisfatória: as taxas de acerto foram de 44.9\% e 45.7\% para os corpora inglês e francês respectivamente. Treinando com o \ensuremath{39^o} e testando com o \ensuremath{36^o}, as taxas de acerto foram ainda piores: 36.8\% e 35.2\% para os corpora inglês e francês respectivamente.  

Diante disso, os autores concluem que as ideologias liberal e conservadora não são exploradas adequadamente pelos discursos. Se o fossem, e considerando que elas não mudaram significativamente de um parlamento para o outro, estes últimos experimentos apresentariam resultados melhores. Eles indicam que os discursos envolvem muitas expressões de ataque e defesa, que mudam de partido conforme eles se alternam no poder. Por este motivo, os conjuntos de treinamento e teste apresentam padrões de ataque e defesa invertidos, implicando no mau desempenho da classificação. Esse trabalho alerta, portanto, para a definição adequada de que perspectivas estão contidas no corpus. Neste caso, em vez de liberal e conservadora, seria mais adequado utilizar pró-governo e anti-governo, por exemplo, ou situação e oposição. % fixam as palavras que ocorrem menos frequentemente nos corpora foram removidas, e um SVM foi aplicado.

O trabalho de \textbf{Klebanov, Beigman e Diermeier} avalia o desempenho dos classificadores Naïve Bayes e SVM, utilizando para isso algumas variações de contagens de palavras \cite{klebanov}. Para o Naïve Bayes, os autores comparam a escolha entre (1) ausência/presença de palavras e (2) contagens de palavras. Para o SVM, as comparações envolvem a escolha entre (1), (3) suas contagens normalizadas em relação ao documento (frequências) e (4) suas frequências ponderadas em relação aos outros documentos do corpus. Os autores selecionaram quatro \emph{datasets} para comparar essas escolhas: o primeiro envolve debates sobre o aborto, dividido entre pró-escolha e pró-vida; o segundo consiste em artigos sobre a pena de morte, dividido entre pró pena de morte e anti pena de morte; o terceiro é composto de artigos sobre o conflito Israel-Palestina, escritos por convidados do \emph{site} Bitterlemons e estudados por Lin et al. \cite{lin-et-al2006}; o quarto também é composto de documentos desse \emph{site}, cada um escrito por um especialista diferente. Esses dois últimos, assim como no trabalho de Lin et al., são divididos entre pró-Palestina e pró-Israel. 

No caso do Naïve Bayes, o uso de (1) se mostrou melhor em alguns \emph{datasets} e o de (2), em outros. A maior diferença de desempenho observada está relacionada com o corpus de pena de morte: com (1), a taxa de acerto obtida foi de 88\%; com (2), 93\%. Quanto ao SVM, a escolha por (1) se mostrou superior ou equivalente às outras em todos os casos.  A maior diferença de desempenho observada também está associada ao corpus de pena de morte: enquanto (1) conduz a uma taxa de acerto de 83\%, (3) resulta em 82\% e (4) em 73\%. Esse trabalho, assim como o de Durant e Smith \cite{durant-smith}, também investiga o uso de um subconjunto de palavras. Com o apoio do \emph{toolkit} WEKA, os autores selecionam subconjuntos pequenos, contendo entre 100 e 500 palavras, e indicam que a classificação dos \emph{datasets}, nestes casos, conserva seu desempenho. As taxas de acerto não aumentam, como no trabalho de Durant e Smith, mas também não diminuem. Todos os resultados apresentados foram obtidos via validação cruzada \emph{10-fold}.

% Os autores indicam, diante disso, que a escolha por qualquer uma dessas alternativas não é tão relevante para problemas de classificação por perspectiva.


%esses dois pontos de vista. Inicialmente, foi feita uma seleção de \emph{blogs} baseada no \emph{site The Moderate Voice}\footnote{http://themoderatevoice.com/}. Este \emph{site} elenca \emph{blogs} de esquerda, direita e moderados. Para esse trabalho, Durant e Smith exploraram apenas os \emph{blogs} de esquerda e direita. Em seguida, apenas os \emph{posts} que tratavam de Bush e da Guerra do Iraque foram separados para classificação. O material foi dividido por mês, devido à grande quantidade de \emph{posts}. Esse trabalho assume que \emph{blogs} de esquerda concentram o ponto de vista anti-Bush,  no que diz respeito a suas atitudes quanto à Guerra do Iraque. \emph{Blogs} de direita, por sua vez, concentram o ponto de vista pró-Bush. 


%O tutorial de Resnik e Hardisty sobre Naïve Bayes e LSPM sugere algumas equações para a implementação deste último \cite{resnik}, mas o próprio Resnik afirmou, em \emph{e-mail} endereçado à autora desta monografia, nunca ter conseguido replicar os resultados apresentados por Lin et al. \cite{email}. Aparentemente, portanto, o LSPM não é tão simples de implementar quanto o Naïve Bayes.  Lin et al. concluem, diante dessas comparações, que o LSPM apresenta desempenho superior ao do Naïve Bayes. N


%Os artigos foram extraídos do \emph{site} Bitterlemons\footnote{http://www.bitterlemons.org/} e estão divididos entre \emph{Palestinian} ou \emph{Israeli}. Os primeiros defendem pontos de vista pró-Palestina; os segundos, pró-Israel. Essa divisão é explorada mais à frente, de modo que o




\section{Trabalhos que exploram outras características dos documentos}
\label{sintaxe}

Esta seção apresenta cinco trabalhos que quantificam outras características dos documentos, a fim de identificar seus pontos de vista. Elas abrangem escolhas sintáticas ou semânticas dos autores dos documentos, como nos trabalhos de Greene e Resnik \cite{resnik} ou Jiang e Argamon \cite{jiang-argamon}, ou a forma como dois ou mais documentos interagem, como no trabalho de Efron \cite{efron}. Os trabalhos dessa seção assumem que as escolhas gramaticais nos documentos, bem como a forma com que eles interagem, contribuem de forma determinante na identificação de seus diferentes pontos de vista. Greene e Resnik inclusive citam as sentenças \emph{Man suffocates 24-year old woman} e \emph{Suffocation kills 24-year-old woman}, que não se contradizem, para evidenciar como escolhas sintáticas mudam suas conotações \cite{greene} - algo intimamente relacionado com expressão de pontos de vista.

O trabalho de \textbf{Greene e Resnik} enfoca no estudo de um corpus sobre a pena de morte \cite{greene}. Esse corpus é posteriormente analisado no trabalho de Klebanov, Beigman e Diermeier \cite{klebanov}, apresentado na seção anterior. O objetivo do trabalho é classificá-lo de acordo com os pontos de vista pró pena de morte e anti pena de morte, e a metodologia desenvolvida baseia-se na hipótese de que existe uma conexão entre a estrutura \emph{sintática} de uma sentença e seu ponto de vista. Neste sentido, os autores selecionam um conjunto de verbos relevantes no corpus, como \emph{kill} e \emph{murder}, e criam representações para todos os termos que se relacionam sintaticamente com eles. Essas representações consistem em tuplas que associam os termos a papéis sintáticos, como \emph{sujeito}, \emph{objeto direto}, \emph{verbo transitivo}, dentre outros. Na tupla, ou o termo corresponde sintaticamente ao papel associado ou se subordina a algum termo que possui esse papel. Dada a frase \emph{Aline matou uma mosca}, por exemplo, o método primeiro gera as relações de dependência (\emph{Aline, matou}) e (\emph{matou, uma mosca}) para, em seguida, destrinchá-las nas tuplas (\emph{Aline, sujeito}), (\emph{sujeito, matou}), (\emph{matou, verbo transitivo}), (\emph{verbo transitivo, uma mosca}) e (\emph{uma mosca, objeto direto}). A determinação dessas tuplas foi feita com o apoio do programa \emph{Stanford Parser}\footnote{http://nlp.stanford.edu/software/lex-parser.shtml}, adaptado à língua inglesa. 

Greene e Resnik então aplicam um SVM nos documentos reduzidos a essas representações. Conforme apresentado no Capítulo \ref{basicos}, o SVM representa o documento numericamente, como um vetor em um espaço multi-dimensional. Embora os autores não indiquem, os valores numéricos provavelmente correspondem às contagens dessas tuplas nos documentos, ou a algo similar. As taxas de acerto obtidas por Greene e Resnik foram de 82.09\% e 88.10\%, a depender da escolha de verbos. Para comparar sua metodologia, os autores aplicam o SVM a documentos representados como sequências de duas palavras (bigramas), todas reduzidas a seus radicais. Nesse caso, o SVM provavelmente explora as contagens desses bigramas nos documentos, ou algo similar, e obtém taxas de acerto de 68.37\% e 71.96\%, também a depender da escolha dos verbos. Todos os resultados apresentados pelos autores foram obtidos via validação cruzada \emph{4-fold}. O uso das tuplas, portanto, trouxe uma melhoria muito significativa para a classificação desse corpus, ainda que esteja intimamente relacionada a uma língua específica.

O trabalho de \textbf{Jiang e Argamon} constrói um corpus de documentos extraídos de \emph{blogs} sobre política escritos em inglês \cite{jiang-argamon}. Cada \emph{blog} é associado ao ponto de vista liberal ou conservador, divisão explorada na classificação. Os documentos que constituem o corpus são apenas as páginas iniciais de cada um deles. Inicialmente, Jiang e Argamon aplicam um SVM às páginas, considerando apenas a ausência/presença de palavras nos documentos. A taxa de acerto obtida foi de 81.92\% e, considerando ambas as classes, tem-se que a precisão média foi de 81.76\%, a recuperação média foi de 81.93\% e a métrica F1 média foi de 81.79\%. Em seguida, as páginas foram reduzidas a suas sentenças subjetivas, através de uma seleção baseada no dicionário semântico \emph{General Inquirer}\footnote{http://www.wjh.harvard.edu/~inquirer/}. Para uma sentença ser escolhida, ela deveria conter pelo menos duas palavras categorizadas, segundo o dicionário, como pertencentes às categorias \emph{Dor}, \emph{Hostilidade}, \emph{Prazer} ou \emph{Virtude}, dentre outras. A taxa de acerto, neste cenário, subiu para 83.28\%. As precisão, recuperação e métrica F1 médias foram de, respectivamente, 83.26\%, 83.38\% e 83.24\%. 

Esse trabalho, por fim, busca extrair as expressões opinativas que mais se relacionam aos pontos de vista liberal e conservador, baseando-se nas sentenças subjetivas e em consultas ao dicionário \emph{General Inquirer}. O SVM é aplicado considerando a ausência/presença de palavras e, adicionalmente, a ausência/presença das expressões opinativas separadas para cada lado. A taxa de acerto neste cenário foi de 84.96\%. As precisão, recuperação e métrica F1 médias foram de, respectivamente, 83.24\%, 83.48\% e 83.27\%. Todos os resultados apresentados por Jiang e Argamon foram obtidos via validação cruzada \emph{10-fold}. As melhorias em relação ao uso exclusivo de ausência/presença de palavras, portanto, são pequenas. Além disso, essas metodologias não são facilmente adaptáveis a línguas que não dispõem de dicionários como o \emph{General Inquirer} \emph{online}.

%Apesar de melhorarem a taxa de acerto obtida inicialmente, essas metodologias são completamente dependentes da língua em que o corpus está escrito. Elas não são  % Os \emph{blogs} foram escolhidos de acordo com cinco catálogos \emph{online}: BlogCatalog, Blogorama, eTalkingHead, Campaigns and Elections e Best of the Web Blogs\footnote{http://blogcatalog.com, http://blogarama.com, http://etalkinghead.com, http://campaignsandelections.com e http://blogs.botw.org.}. A finalidade desse trabalho, portanto, é determinar o posicionamento político desses \emph{blogs}, considerando seu conteúdo mais imediato - suas páginas iniciais. %As metodologias empregadas são completamente dependentes da linguagem do corpus, por utilizarem dicionários desenvolvidos para o inglês. % português.


%  papel sintático. Esses papéis, por sua vez, podem ser

O trabalho de \textbf{Efron} constrói dois \emph{datasets}: um envolvendo artigos sobre a política dos Estados Unidos e outro composto de textos sobre artistas musicais \cite{efron}. O primeiro corpus é classificado de acordo com os pontos de vista direita e esquerda e o segundo, de acordo com as orientações pró-alternativa ou pró-popular. Inicialmente, Efron classifica os dois corpora com um Naïve Bayes e um SVM. O autor não especifica se são utilizadas contagens de palavras ou alguma outra característica, mas afirma que os dois métodos \emph{se baseiam em palavras}. Com o Naïve Bayes, as taxas de acerto obtidas nestes corpora foram de, respectivamente, 64.71\% e 50.1\%. Para o primeiro corpus, a taxa de acerto obtida com um SVM foi de 72.96\%; quanto ao segundo, não foram realizados experimentos com o SVM por carência de recursos computacionais. A fim de melhorar as taxas de acerto,  Efron desenvolve uma classificação baseada em citações que não envolve contagens de palavras nem citações de um documento a outro, mas sim suas semelhanças temáticas. 

Na prática, Efron determina o posicionamento de cada documento de acordo com a probabilidade deles serem co-citados com  documentos fixados como referência para cada ponto de vista. Essa probabilidade é estimada a partir dos números de documentos retornados pelo buscador AltaVista\footnote{http://altavista.com/} quando dois documentos são buscados, indicando co-citação entre eles. Essa metodologia de classificação, aplicada ao primeiro \emph{dataset}, resultou em uma taxa de acerto de 94.1\%. Quanto ao segundo, as taxas de acerto obtidas foram de 82.18\% e 88.84\%. No primeiro caso, todos os documentos foram considerados; no segundo, os menos co-citados foram descartados. Apesar de simples e aparentemente eficiente, essa metodologia apresenta uma séria limitação: se o corpus for composto de documentos pouco citados na Web, as classes podem ser estimadas erroneamente com uma alta frequência, não trazendo nenhuma melhoria significativa à classificação.

O trabalho de \textbf{Thomas, Pang e Lee} se propõe a determinar os pontos de vista de congressistas dos Estados Unidos quanto a novas leis \cite{get-out-the-vote}. O corpus é dividido entre os posicionamentos suporte e oposição em relação a novas leis, e cada documento corresponde, a princípio, a uma fala de um congressista. Inicialmente, cada texto é classificado de forma isolada, através da aplicação de um SVM que considera a ausência/presença de palavras em cada um deles. As taxas de acerto obtidas foram de 66.05\% e 70.04\%, a depender do subconjunto de documentos classificado. Tratando cada documento como a concatenação de todas as falas de um mesmo congressista, as taxas obtidas com o SVM, considerando as mesmas características, foram de 70.00\% e 71.60\%. A fim de melhorar essas taxas de acerto, os autores comparam trechos de documentos e determinam valores positivos que representam o quanto eles concordam. Quando esses valores são menores do que um determinado \ensuremath{\theta} fixado, considera-se que não há indícios suficientes de que os documentos concordam; eles são, então, reduzidos a zero. Adicionalmente, os autores aproveitam os experimentos com o SVM para determinar o grau de preferência para classificar cada documento como suporte ou oposição. 

A classe escolhida para cada um deles, no novo esquema, deve ser aquela que favorece o seguinte cenário: (1) ela não deve, idealmente, ser a rejeitada pelo SVM e (2) documentos que concordam muito não devem ser associados a classes diferentes. As taxas de acerto obtidas, considerando cada documento como uma fala, variaram entre 70.81\% e 89.11\%, a depender do subconjunto classificado e do valor de \ensuremath{\theta}. Considerando cada documento como a concatenação de todas as falas de um mesmo congressista, as taxas de acerto obtidas variaram entre 71.28\% e 88.72\%, também a depender do subconjunto classificado e do valor de \ensuremath{\theta}. A determinação errônea de concordâncias entre documentos pode prejudicar significativamente a classificação. Além disso, de acordo com os próprios autores, a adoção dessa metodologia só traz benefícios quando há artigos difíceis de classificar individualmente.    

O trabalho de \textbf{Bansal, Cardie e Lee} propõe uma extensão ao trabalho de Thomas, Pang e Lee \cite{get-out-the-vote}, considerando também a \emph{discordância} entre documentos \cite{disagree}. A hipótese assumida em ambos os trabalhos é a mesma: se é difícil determinar a classe de um documento \emph{x}, mas sabe-se que ele concorda \emph{ou discorda} de um documento \emph{y}, fácil de classificar, a determinação da classe de \emph{x} também se torna mais fácil. O trabalho apresenta algumas estratégias para determinação dos valores de discordância e, em seguida, compara seus usos com a metodologia proposta por Thomas, Pang e Lee. Bansal, Cardie e Lee também lidam com valores negativos, associados à discordância. Na prática, é preciso mapear esses valores negativos em positivos, pois eles dificultam o problema de otimização envolvido na determinação das classes dos documentos. Esses mapeamentos são justamente o que diferencia uma estratégia de outra. Utilizando o mesmo \emph{dataset} analisado por Thomas, Pang e Lee, os autores deste trabalho obtêm resultados superiores ou equivalentes àqueles que consideram apenas a concordância entre documentos, para a maioria das estratégias testadas. As taxas de acerto, entretanto, não são informadas explicitamente neste trabalho, sendo representadas através de um gráfico comparativo.
%convote e disagree
%decidem considerar o quanto congressistas diferentes \emph{concordam}. Neste sentido, os autores 



\section{Análise comparativa}
\label{compara}

Os trabalhos revisados neste capítulo propõem, em quase todos os casos, \emph{datasets} relacionados com questões políticas. Neste sentido, o trabalho de \textbf{Efron}, revisado na seção \ref{sintaxe}, destaca-se por também abordar pontos de vista sobre música (pró-alternativa e pró-popular) \cite{efron}. De fato, não é simples definir o que é um ponto de vista ou perspectiva, mas, considerando-se a discussão proposta na \emph{survey} de Pang e Lee \cite{omsa}, essas terminologias não abrangem apenas temáticas políticas - mesmo que seja mais fácil visualizá-las nesses contextos. Adicionalmente, Alice Oh, em seu trabalho sobre modelagem de perspectiva, aborda uma temática esportiva (jogos de \emph{baseball}) \cite{alice-oh}. Embora ela não lide com classificação, seu estudo envolve as perspectivas sobre os jogos, evidenciando que é possível explorar temáticas não-políticas. Seria interessante, portanto, ampliar os estudos de classificação por ponto de vista para outros domínios sócio-culturais. Por fim, é importante escolher esses pontos de vista com certo cuidado, de modo que eles correspondam efetivamente ao conteúdo do corpus. Neste sentido, o trabalho de \textbf{Hirst, Riabinin e Graham}, apresentado na seção \ref{contagem}, apresenta uma boa discussão \cite{hirst-et-al}. 

Quanto à definição dos pontos de vista, todos os trabalhos revisados dividiram seus corpora em \emph{dois} deles, associando cada um a uma classe.  Talvez a exploração de temáticas políticas tenha favorecido esse recorte, mas é importante ressaltar que, em tese, nada impede estudos em \emph{datasets} com mais pontos de vista. No que diz respeito ao pré-processamento dos documentos, destaca-se o segundo trabalho de \textbf{Mullen e Malouf}, apresentado na seção \ref{contagem} \cite{malouf-taking_sides}. Apesar da classificação em si ser simples, baseando-se apenas em contagens de palavras, a geração dos documentos envolve a formulação de um grafo e a análise de padrões de citação semelhantes. É válido reforçar que essa estratégia só é válida em cenários onde há muitas citações e padrões razoavelmente diferentes. Se todos os documentos se citam de forma semelhante, a geração de agrupamentos significativos pode ser prejudicada. 

No que diz respeito aos classificadores, foi observado que não há consenso quanto à escolha pelo Naïve Bayes ou por um SVM, principais técnicas abordadas. Aparentemente, o desempenho de ambos não difere muito; o que realmente apresenta um impacto na classificação é a escolha das características dos documentos, exploradas por algum dos classificadores. De todo modo, \textbf{Lin et al.} destaca, em seu trabalho revisado na seção \ref{contagem}, o desenvolvimento de um novo classificador, o LSPM \cite{lin-et-al2006}. Esse classificador apresenta um desempenho apenas um pouco superior ao do Naïve Bayes, além de não ter sido explorado por nenhum outro trabalho pesquisado. Por outro lado, os trabalhos de Efron, \textbf{Thomas, Pang e Lee} e \textbf{Bansal, Cardie e Lee} apresentam metodologias de classificação completamente diferentes do Naïve Bayes e dos SVMs, e obtêm melhorias significativas em seus resultados \cite{efron, get-out-the-vote, disagree}. Essas metodologias, entretanto, exploram valores associados às interações entre documentos: quando elas não são significativas, essas metodologias podem não ser úteis.  

Os trabalhos revisados exploram características diferentes dos documentos e, até quando exploram as mesmas, podem escolher apenas um subconjunto delas ou investir no pré-processa mento dos documentos. Tudo isso contribui para a riqueza metodológica desses trabalhos, de modo que ainda não há consenso sobre qual é a melhor forma de classificar documentos de acordo com seus pontos de vista. Aparentemente, a resposta para essa questão depende do cenário. Em alguns casos, a simples aplicação de um Naïve Bayes ou de um SVM, explorando-se apenas contagens de palavras ou alguma variação, já conduz a bons resultados. É o caso dos trabalhos de Lin et al., Hirst, Riabinin e Graham e \textbf{Klebanov, Beigman e Diermeier}, revisados na seção \ref{contagem}, e de \textbf{Jiang e Argamon}, revisado na seção \ref{sintaxe} \cite{lin-et-al2006, hirst-et-al, klebanov, jiang-argamon}. Em outros casos, é possível melhorar o desempenho utilizando-se \emph{ainda} apenas as contagens de palavras ou alguma variação. Nestes casos, a estratégia pode envolver mudar o pré-processamento dos documentos, como fazem Mullen e Malouf em seu segundo trabalho, ou escolher um subconjunto ótimo de palavras, como no trabalho de \textbf{Durant e Smith} \cite{malouf-taking_sides, durant-smith}.

Quando essas mudanças não são suficientes, os autores dos documentos analisados não estão consolidando seus pontos de vista, de forma suficiente, no nível das palavras. Ou seja, em um nível no qual se despreza qualquer aspecto semântico ou sintático dos documentos. É provável que, nestes cenários,  as palavras estejam ocorrendo nos textos de forma muito semelhante, de modo que suas contagens (ou alguma variação das contagens), no contexto dos classificadores, não são suficientes para uma discriminação adequada dos pontos de vista. Nestes casos, sugere-se a investigação de outras características dos documentos, como indicam os trabalhos de \textbf{Greene e Resnik}, Efron e Thomas, Pang e Lee, revisados na seção \ref{sintaxe} \cite{greene, efron, get-out-the-vote}.

 O uso de outras características pode envolver a aplicação de \emph{softwares} de apoio ou consultas a dicionários semânticos adaptados a \emph{línguas específicas}, como evidenciam os trabalhos de Greene e Resnik \cite{greene} e Jiang e Argamon \cite{jiang-argamon}, e nem sempre apresentam uma melhoria significativa em relação a metodologias mais simples, como nesse último caso (aproximadamente 3\% de aumento em relaçao a um SVM baseado em ausência/presença de palavras). A exploração da forma como documentos interagem ou são co-citados também pode ser desaconselhável em cenários onde as co-citações, ou interações, não são expressivas. Essa exploração pode criar ruídos na classificação, em vez de efetivamente indicar semelhanças úteis para a identificação correta das classes dos documentos. %na taxa de acerto obtida com .

%A Tabela 3.1 apresenta, de forma sintética, alguns dos principais aspectos dos trabalhos revisados neste capítulo. Seu objetivo é compactar as observações feitas sobre esses trabalhos, facilitando uma comparação rápida e simplificada entre eles.

%\begin{table}[t]
%\centering
%\begin{tabular}{|p{2.5cm} | p{3cm} | p{2.2cm} | p{3cm} | p{3cm} | }
%\hline
%\textbf{Trabalho} & \textbf{Tema} & \textbf{Classificador} & \textbf{Características exploradas} & \textbf{Taxa de acerto} \\ \hline
%\textbf{Lin et al.} & Conflito Israel-Palestina & SVM, Naïve Bayes, LSPM & Variação de contagens de palavras  & Entre 81.48\% e 99.09\% \\ \hline
%\textbf{Mullen e Malouf} (\ensuremath{1^o} trabalho) & Política dos Estados Unidos & Naïve Bayes & Contagens de palavras  & 60.37\% \\ \hline
%\textbf{Mullen e Malouf} (\ensuremath{2^o} trabalho) & Política dos Estados Unidos & Naïve Bayes & Contagens de palavras  & 73.00\% \\ \hline
%\textbf{Durant e Smith} & George W. Bush e a Guerra do Iraque & SVM & Variação de contagens de palavras & Entre 75.47\% e 89.77\% \\ \hline 
%\textbf{Hirst, Riabinin e Graham} & 
%\textbf{Pró-situação} & serra, dilma, lula, psdb, presidente, pt, candidato, folha, tucano, rio, eleições, partido, jornal, campanha, pesquisa \\ \hline
%\textbf{Pró-oposição} & dilma, lula, presidente, brasil, rousseff, rio, pt, gente, candidata, mundo, candidato, petista, entrevista, partido, josé \\ \hline
%\end{tabular}
%\label{compara}
%\caption{Comparação sintética entre os trabalhos.}
%\end{table}
 

 
%\section{Discussão sobre o uso de palavras e a classificação baseada em suas contagens}
%\label{freqs:experim}


%Boa parte dos trabalhos revisados na seção anterior classifica documentos explorando suas diferentes contagens de palavras. Eles se baseiam, ainda que não intencionalmente, na hipótese de que indíviduos com posicionamentos diferentes se expressam de formas distintas, dando ênfase a palavras diferentes. Essa hipótese, é importante frisar, encontra respaldo na área de Linguística \cite{teubert}. Embora os aspectos gramaticais dos documentos, ou suas interações com outros, também possam colaborar na identificação de pontos de vista diferentes, muitas vezes já é possível obter bons resultados considerando-se apenas a forma como as palavras ocorrem nos documentos. Este foi o caso de uma parte significativa dos trabalhos revisados na seção anterior. Além disso, não houve sequer dois trabalhos, na seção anterior, que tenham explorado outros aspectos dos documentos da mesma forma, o que reforça a ideia de que o uso de contagens de palavras - ou variações, como a ausência/presença de palavras\footnote{Conforme apresentado no Capítulo \ref{basicos}, dado um documento, a ausência/presença de uma palavra corresponde a um valor \emph{booleano}, que indica se ela está ausente (0) ou presente (1) nele \cite{mccallum-nigam}.} - é, atualmente, a escolha mais natural para classificação por ponto de vista. 

%Diante desses pontos, essa seção se propõe a ampliar a compreensão sobre classificações baseadas em contagens de palavras. A ideia é aprofundar o entendimento sobre o desempenho obtido nesse tipo de classificação, observando a forma como documentos, escritos sob pontos de vista diferentes, empregam palavras. Parte-se da seguinte evidência: se um classificador utiliza \emph{apenas} as contagens de palavras dos documentos para identificar seus pontos de vista, sua taxa de acerto é tão mais baixa quanto menos essas contagens mudam de um ponto de vista para outro. Apesar dessa relação ser clara, não se conhece nenhum método para \emph{quantificá-la}.  O objetivo dessa seção, portanto, é \emph{ilustrá-la} através de alguns experimentos. Neste sentido, é feita uma comparação entre o uso de palavras em dois \emph{datasets}, classificados com um Naïve Bayes que explora apenas suas contagens. Para a análise do uso das palavras, será utilizado o modelo de tópicos L-LDA\footnote{O L-LDA é apresentado no Capítulo \ref{basicos}.}. 

%%%%%%%%%%%%%%%%%%%%%%% NAIVE BAYES
%A escolha pelo Naïve Bayes, em vez de um SVM, advém da ideia de que, na seção anterior, ambos os classificadores apresentam desempenho semelhante. Em alguns casos, o primeiro funciona melhor do que o segundo; em outros, tem-se a situação contrária. Para os propósitos dessa seção, não houve necessidade de comparar o desempenho dos dois classificadores. Um ponto que reforça a escolha pelo Naïve Bayes é o trabalho de Ng e Jordan, que indica o uso desse classificador quando os \emph{datasets} analisados são pequenos \cite{ng-jordan}. Este é o caso de um dos corpora analisados. %, esse argumento reforça a escolha pelo Naïve Bayes.


%Para isso, os resultados obtidos em dois cenários serão analisados à luz das palavras mais destacadas por cada perspectiva. 
% Em outras palavras, isso significa que, em corpus nos quais os documentos usam as palavras de forma muito parecida (contagens semelhantes), a classificação se torna mais difícil.
%como a contagem de uma palavra é o número de vezes que ela ocorre,
 %Sendo assim, recomenda-se que, antes de explorar outras características, verifique-se o desempenho da classificação baseando-se exclusivamente nestas.

%A escolha por contagens de palavras, em vez de alguma ausência/presença ou alguma outra variação, se deveu à sua maior relevância nos trabalhos revisados, não há indícios de que uma das alternativas seja, em termos gerais, melhor do que outra. 
%A fim de entender melhor a relação entre a classificação baseada em contagens de palavras comoDiante disso, e do fato de que contagens, em particular, são simples de computar e independem de qualquer língua, essa seção discute a relação entre o uso de palavras nos documentos
%Um classificador que explora contagens de palavras, portanto, se baseia nas contagens das palavras de todos os documentos. Suas determinações, portanto, não dependem de nenhuma análise gramatical. O mesmo vale para suas variações, como ausência/presença de palavras. Neste caso, o classificador não conta quantas vezes cada palavra ocorre em um dado documento, mas avalia se ela está ausente ou presente.
%Dada a importância que as contagens têm, no contexto dos trabalhos revisados na seção anterior, e considerando a ideia de que elas quantificam posicionamentos difere estão intimamente relacionadas com as diferentes ênfases que 

%Conforme discutido na seção anterior, contagens de palavras e algumas variações são as características \emph{mais exploradas} na classificação. Nem todos os trabalhos enfocam essas características, mas grande parte, no mínimo, compara suas metodologias com o uso de um Naïve Bayes ou SVM baseado nelas. Além de envolver apenas cálculos simples, o uso de contagens de palavras ou variações torna a classificação facilmente adaptável a \emph{datasets} escritos em qualquer língua. Trabalhos como os de \textbf{Greene e Resnik} e \textbf{Jiang e Argamon} \cite{greene} \cite{jiang-argamon}, revisados na subseção \ref{sintaxe}, evidenciam o quanto o uso de características sintáticas/semânticas depende da existência de \emph{softwares} ou dicionários de apoio, direcionados a uma língua específica. O uso de contagens de palavras, em particular, não depende de nada disso. Por fim, além de simples, o uso de contagens de palavras, ausência/presença de palavras ou variações muitas vezes conduz a bons resultados, como indicado na seção anterior. Diante desses fatores, 



%Como o seu entendimento amplia a compreensão dos resultados obtidos com esses classificadores, esta seção se detém a ilustrá-la através de alguns experimentos.
%APRESENTE OS DOIS DATASETS. JUSTIFIQUE PQ REFEZ EXPERIMENTOS OU PQ N ESCOLHEU O AAAI E SIM OUTRO. - OK 


%O primeiro \emph{dataset} estudado é composto de artigos sobre o conflito Israel-Palestina\footnote{Esse corpus está disponível em http://sites.google.com/site/weihaolinatcmu/data}, estudado pela primeira vez por Lin et al. em trabalho revisado na seção anterior \cite{lin-et-al2006}. O segundo \emph{dataset} estudado provém de outro trabalho: o artigo de Thomas, Pang e Lee sobre debates de congressistas dos Estados Unidos\footnote{Esse corpus está disponível em http://www.cs.cornell.edu/home/llee/data/convote.html}, também apresentado na seção anterior \cite{get-out-the-vote}. O primeiro \emph{dataset} contém 594 artigos, divididos entre os posicionamentos pró-Israel (297) e pró-Palestina (297); o segundo, 8126 falas em debates, dividos entre os pontos de vista republicano (4044) e democrata (4046). Esse corpus também se divide entre os pontos de vista suporte e oposição em relação a novas leis, explorados por Thomas, Pang e Lee. Nessa seção, a primeira divisão é adotada por questões didáticas. Assume-se que o público desse trabalho está mais familiarizado com posicionamentos republicanos ou democratas, amplamente divulgados nas mídias, do que com aqueles da segunda divisão. Isso fará diferença na compreensão da análise de palavras proposta nessa seção.

%Inicialmente, considerando-se essas divisões dos \emph{datasets}, experimentos com o Naïve Bayes foram conduzidos. Não foi feito nenhum pré-processamento nos corpora, simplificando ainda mais a metodologia dessa classificação. Via validação cruzada de dez dobras, a taxa de acerto obtida para o primeiro corpus foi de 86.22\%; para o segundo, de 54.01\%. A investigação sobre como as palavras são empregadas nesses \emph{datasets}, divididas por pontos de vista, amplia a compreensão sobre esses resultados.

%MOSTRE COMO OS MODELOS DE TÓPICOS SÃO USADOS NOS DOIS LADOS - ok

%Para a investigação sobre o uso de palavras, foi feita uma aplicação do modelo L-LDA. Cada documento de ambos os \emph{datasets} foi associado a dois tópicos: um neutro, idêntico para todos eles, e outro referente a seu ponto de vista. No primeiro corpus, esses pontos de vista são pró-Israel ou pró-Palestina; no segundo, republicano ou democrata. Há portanto, em cada corpus, três tópicos diferentes. O uso de um tópico neutro, associado a todos os documentos, ajuda a filtrar palavras muito comuns nos \emph{datasets}, independentemente de ponto de vista. Essa é a diferença fundamental entre essa aplicação do L-LDA e a simples contagem de palavras em documentos, dividida entre os dois pontos de vista. Esse tipo de contagem não diferencia quais palavras são \emph{mais destacadas} em documentos escritos sob uma certa perspectiva e quais são \emph{muito utilizadas} por todos eles - informação que colabora para um maior entendimento das taxas de acerto supracitadas, obtidas com um Naïve Bayes. Para os propósitos dessa seção, não é necessário analisar o tópico neutro: ele apenas colabora no processo de evidenciar as palavras mais importantes, por ponto de vista. É válido ressaltar que, em alguns casos, essas palavras coincidem para os dois pontos de vista. Nestes casos, ambos dão muito destaque a elas.

%MOSTRE AS PALAVRAS ELENCADAS E DISCUTA

%As dez palavras mais frequentemente associadas a cada ponto de vista, retirando-se artigos, conjunções, preposições, advérbios e pronomes pessoais, estão listadas nas Tabelas 3.1 e \ref{freqs:tab2}. Apesar de pequenas, essas listagens sugerem interpretações sobre como as palavras de cada corpus são exploradas por seus diferentes pontos de vista. Essas interpretações, essencialmente  subjetivas, ajudam a entender o comportamento do classificador Naïve Bayes aplicado aos dois \emph{datasets}.%colaboram parsubjetiva de se ampliar a discussão sobre os resultados obtidos com o Naïve Bayes.

%provêem informações subjetivas sobre a linguagem empregada nos corpora.
%As palavras extraídas a partir da aplicação de um L-LDA  Ainda assim, essas informações 

%Para ilustrar a relação que existe entre as taxas de acerto do Naïve Bayes e o uso de palavras nesses corpora, a

%As análises feitas a partir dessas pequenas listagens são essencialmente subjetivas, sugerindo interpretações %sugerindo  Essa análise não pretende  % A partir disso, espera-se compreender melhor o 

%\begin{table}[h]
%\label{tab1}
%\centering
%\begin{tabular}{| l | p{10cm} | }
%\hline
%\textbf{Tópico} & \textbf{Palavras} \\ \hline
%\textbf{Pró-Israel} & sharon, palestinian, arafat, peace, israeli, prime, bush, minister, american, process \\ \hline
%\textbf{Pró-Palestina} & palestinian, israeli, sharon, peace, occupation, international, political, united, people, violence \\ \hline
%\end{tabular}
%\caption{As dez palavras mais frequentemente associadas aos tópicos pró-Israel e pró-Palestina, de acordo com um L-LDA.}
%\end{table}
%\textbf{Genérico} & israel, palestinian, israeli, palestinians, state, one, two, israelis, political, right \\ \hline


%Considerando o primeiro corpus, as palavras associadas aos pontos de vista pró-Israel e pró-Palestina remetem de imediato ao conflito travado entre essas duas nações. Parte delas, como \emph{palestinian} e \emph{israeli}, são bastante mencionadas por ambos os pontos de vista, ainda que com propósitos diferentes: %israelenses, 

%\begin{quote}

%\emph{"The recent \textbf{Israeli} government decision to begin building extensive walls
%around \textbf{Palestinian} is just one more example of how \textbf{Israeli} Prime
%Minister Ariel Sharon is unable to deal with \textbf{Israeli} problems save
%through his narrow security vision."}

%{\small Retirado de "Peace in peaces", de Ghassan Khatib (pró-Palestina) - 10/06/2002}
%\end{quote}

%\begin{quote}

%\emph{"The first conclusion that the Israeli political and security
%establishment should learn and internalize after 18 months of
%\textbf{Palestinian} Intifada, concerns the intensity of \textbf{Palestinian} blind
%terrorism and guerilla warfare against the State of Israel."}

%{\small Retirado de "The lessons Israel should learn", de Meir Pa'il (pró-Israel) - 29/04/2002}
%\end{quote}

%\emph{"Meanwhile, the Israeli army was still suffering in South Lebanon as a result of the dilemma that \textbf{Sharon} put them in."}

%{\small Retirado de "Sharon settles accounts", de Mamdouh Nofal (pró-Palestina) - 28/01/2002}

%Outras palavras, como \emph{bush} e \emph{occupation}, foram mais enfatizadas, respectivamente, pelos pontos de vista pró-Israel e pró-Palestina, constando em apenas uma listagem. Os trechos abaixo evidenciam a importância, no período em que os documentos desse corpus foram escritos (2001 - 2005), do Governo Bush para Israel e da criação de um Estado para a nação palestina:
 %\textbf{Falar das figuras e de como elas deixam isso tão claro.} 

%\textbf{FIGURAS} % Para compreender melhor o uso das palavras pelos diferentes pontos de vista do corpus, elas foram processadas pelo software wordle22 , resultando nas figuras 7.1, 7.2 e 7.3. O tamanho das palavras nas imagens corresponde ao quanto elas se associam a cada tópico23 .

%Falar das ênfases no próprio lado/lado oposto e mostrar tb as palavras genéricas.
%Os trechos abaixo, separados por perspectiva, ilustram dois contextos diferentes para o uso dessas palavras

%\begin{quote}
%\emph{"The recent \textbf{Israeli} government decision to begin building extensive walls
%around \textbf{Palestinian} is just one more example of how \textbf{Israeli} Prime
%Minister Ariel Sharon is unable to deal with \textbf{Israeli} problems save
%through his narrow security vision."} 

%{\small Retirado de \emph{"Peace in pieces"}, de Ghassan Khatib - 10/06/2002}
%\end{quote}

%\begin{quote}
%\emph{"The first conclusion that the Israeli political and security
%establishment should learn and internalize after 18 months of
%\textbf{Palestinian} Intifada, concerns the intensity of \textbf{Palestinian} blind
%terrorism and guerilla warfare against the State of Israel."} 

%{\small Retirado de }

%\end{quote}


%\begin{quote}
%\emph{"\textbf{Bush} and his advisers, who have been critical of Clinton's deep involvement
%in a failed peace process ever since taking office, nevertheless
%understood at the time that peace in the Middle East should be beyond
%politics in America, and that the US could not permit itself to turn its
%back on an Israeli leader who was determined to make peace."} 

%{\small Retirado de "Barak was willing, and so were US Jews", de Yossi Alpher (pró-Israel) - 15/07/2002}
%\end{quote}

%\begin{quote}
%\emph{"But just as we were close to a complete
%package that would have ended the \textbf{occupation} and established a
%Palestinian state, Barak permitted Ariel Sharon's provocative visit to
%Al Aqsa mosque, and launched his "revenge" on Palestinians."} 

%{\small Retirado de "Guarding our legitimacy", de Samir Abdullah (pró-Palestina) - 14/10/2002}
%\end{quote}

%Associadas ao tópico genérico, também estão as palavras \emph{palestinian} e \emph{israeli}, bastante exploradas pelas duas perspectivas. Isso reflete a importância que esses termos têm para o corpus como um todo. Palavras relacionadas mais genericamente ao conflito Israel-Palestina, como \emph{state} e \emph{political}, também aparecem na listagem. %, evidenciando indica que essas palavras         


                     % A imagem 7.3 dá certo destaque a Lula e José Serra, mas também enfatiza outros termos, como governo e brasil, relacionados mais genericamente ao tema geral dos artigos: a política brasileira.


%Essas análises, avaliadas à luz das altas taxas de acerto obtidas com o Naïve Bayes, sugerem que os autores desse primeiro corpus defendem seus pontos de vista veementemente. Como eles são antagônicos, isso se reflete em enfoques diferentes a determinados termos, %empregos diferentes de palavras. % tornando a forma como empregam as palavras  defendem suas perspectivas utilizando palavras de forma suficientemente diferentedestacando ideias diferentes.

%\begin{table}[h]
%\label{freqs:tab2}
%\centering
%\begin{tabular}{| l | p{10cm} | }
%\hline
%\textbf{Tópico} & \textbf{Palavras} \\ \hline
%\textbf{Democrata} & bill, security, legislation, states, chairman, country, act, billion, million, law \\ \hline
%\textbf{Republicano} & act, chairman, security, states, bill, legislation, 11, support, 9, system \\ \hline
%\end{tabular}
%\caption{As dez palavras mais frequentemente associadas aos tópicos republicano e democrata, de acordo com um L-LDA.}
%\end{table}

%\textbf{Genérico} & mr., speaker, bill, all, time, people, today, gentleman, federal, support \\ \hline

%Considerando o primeiro corpus, as palavras associadas às perspectivas pró-Israel e pró-Palestina remetem de imediato ao conflito travado entre essas duas nações. Parte delas, como \emph{palestinian} e \emph{israeli}, são bastante mencionadas em ambas as perspectivas, ainda que com \textbf{intensidades} diferentes. \textbf{Falar das figuras e de como elas deixam isso tão claro.} 

%Falar q blz, aparecem palavras diferentes e tb há proporções diferentes, mas oq dá pra notar no geral eh q os termos envolvem pouca polêmica, e são usados de forma parecida. Isso, e o fato da amostra ser pequena, sugere q os debatentes n defendem as perspectivas republicana e democrata de forma suficientemente clara pra q um Naïve Bayes classifique corretamente.

%Considerando o segundo corpus, tem-se que parte das palavras associadas aos pontos de vista republicano e democrata, como \emph{bill}, \emph{legislation}, \emph{states} e \emph{act}, tem mais a ver com o processo legislativo em si do que com algum deles. Isso sugere que os debatentes não focam seus discursos na defesa de ideias republicanas ou democratas. Além disso, algumas dessas palavras são, muitas vezes, empregadas com conotações semelhantes por democratas e republicanos. Um exemplo é a palavra \emph{security}, como pode ser observado nos trechos abaixo

%\begin{quote}
%\emph{"Mr. speaker, I wholeheartedly agree that if we want to cut down on illegal immigration, we must improve border \textbf{security}. Just 2 weeks ago, an astute crane operator at the port of Los Angeles discovered 32 Chinese stowaways in a container that had just been unloaded from a Panamanian freighter."} 

%{\small Retirado de discurso de Jane Harman, democrata - 09/02/2005 }

%\end{quote}

%\begin{quote}
%\emph{"The fence remains incomplete and is an opportunity for aliens to cross the border illegally. This incomplete fence allows border \textbf{security} gaps to remain open.  We must close these gaps because they remain a threat to our national \textbf{security}."}

%{\small Retirado de discurso de John Boozman, republicano - 02/10/2005}

%\end{quote}

%Duas palavras listadas apenas para o ponto de vista republicano, \emph{11} e \emph{9}, podem sugerir um maior enfoque no episódio 11 de Setembro e seus desdobramentos. A palavra \emph{billion}, listada apenas para o ponto de vista democrata, é muitas vezes utilizada para discutir gastos públicos, o que pode indicar um destaque maior para esse assunto

%\begin{quote}
%\emph{We know that all but one of the \textbf{9}/\textbf{11} hijackers acquired some type of U.S. identification documents. In fact, the 19 hijackers had 63 driver 's licenses among them.}

%{\small Retirado de discurso de John Sullivan, republicano - 09/02/2005} 
%\end{quote}

%\begin{quote}
%\emph{The Pomeroy bill would cost the treasury \$72 \textbf{billion} over 10 years, compared with the \$290 \textbf{billion} price tag of a full repeal through 2015, according to the joint committee on taxation.}

%{\small Retirado de discurso de Earl Pomeroy, democrata - 12/04/2005}
%\end{quote}


%As palavras associadas ao tópico genérico, assim como aquelas associadas às perspectivas republicana e democrata, também têm mais a ver com o processo legislativo e a estrutura dos debates do que com posicionamentos políticos. Alguns exemplos são \emph{bill}, \emph{mr.}, \emph{speaker} e \emph{gentleman}. 

%O uso de palavras que pouco têm a ver com os pontos de vista republicano e democrata, como \emph{bill} e \emph{legislation}, reforça a ideia, apresentada por \textbf{Hirst, Riabinin e Graham} em trabalho revisado na seção anterior \cite{hirst-et-al}, de que a divisão entre os pontos de vista republicano e democrata não é muito adequada para este corpus. De todo modo, uma divisão inadequada não necessariamente implica em mau desempenho: em uma classificação, esses autores obtiveram, utilizando uma divisão inadequada de corpus, uma taxa de acerto de 83.8\% \cite{hirst-et-al}. É válido ressaltar que eles utilizam \emph{apenas} contagens de palavras e exploram um \emph{dataset} muito semelhante a este: debates entre congressistas do Canadá. 

%As Tabelas 3.1 e \ref{freqs:tab2} sugerem que os republicanos e democratas estudados no segundo corpus se expressam de forma mais parecida do que os autores do primeiro corpus. Este é o ponto que, de fato, pode contribuir negativamente para a classificação. Talvez isso advenha do fato de que seus discursos fazem parte de debates, o que pode concentrar as discussões em torno de um conjunto muito específico de termos. No primeiro corpus, os autores não escreveram seus artigos como resposta direta a outros, o que pode colaborar para que eles se expressem de forma mais autêntica e veemente, focando seus textos na apresentação de seus pontos de vista. A aplicação do L-LDA, associando cada tópico a um ponto de vista diferente, se mostrou válida, evidenciando uma certa homogeneização no uso de palavras no segundo corpus, quando comparado com o primeiro.
  %Associadas ao tópico genérico, há palavras referentes ao processo legislativo e aos debates, como \emph{bill}, \emph{mr.}, \emph{speaker} e \emph{gentleman}. Essas são as palavras mais comuns em todo o corpus - e, como pode ser observado, elas se assemelham às palavras elencadas para as perspectivas. Não apenas porque algumas delas, como blablala, estão listadas para os três tópicos, mas especialmente porque grande parte delas não evidencia um viés republicano ou democrata.%  Essa característica também é observada nas palavras listadas para as duas perspectivas, o que sugere a dificuldade de se identificar as perspectivas republicana ou democrática nos documentos desse segundo corpus. %  estão as palavras \emph{palestinian} e \emph{israeli}, bastante exploradas pelas duas perspectivas. Isso reflete a importância que esses termos têm para o corpus como um todo. Palavras relacionadas mais genericamente ao conflito Israel-Palestina, como \emph{state} e \emph{political}, também aparecem na listagem. 


%As taxas de acerto obtidas com um Naïve Bayes nesse segundo corpus foram baixas. % Ainda que as perspectivas republicana e democrata enfatizem palavras diferentes, conforme pode ser observado na Tabela \ref{freqs:tab2}, as listagens sugerem que elas empregam mais palavras em comum, no decorrer dos debates, do que os artigos  

%As palavras das Tabelas 3.1 e \ref{freqs:tab2} foram representadas graficamente com o apoio do \emph{software} wordle\footnote{http://wordle.net/}. Apesar de se associarem aos tópicos com frequências distintas, o \emph{software} não foi sensível o suficiente para capturar essas diferenças. Por este motivo, essas imagens não constam nessa monografia.


%É válido ressaltar que, a depender do \emph{dataset}, outras questões podem colaborar para um mau desempenho na classificação. Um conjunto de documentos com poucos exemplares, ou contendo poucas palavras, é um cenário onde a aplicação do Naïve Bayes pode não funcionar bem. Entretanto, esse não parece ser o caso dos corpora analisados nessa seção. De todo modo, quando não se obtém uma boa taxa de acerto com um classificador baseado em contagens de palavras, a investigação subjetiva de como cada ponto de vista faz uso delas pode ajudar na compreensão do fenômeno. Nesses casos, é preciso buscar características dos documentos que os diferenciem melhor. 

%O tópico genérico, por sua vez, concentra as palavras mais comuns em todo o corpus. Se elas são muito semelhantes às palavras elencadas para cada perspectiva, isso também pode indicar uma certa homogeneização no uso das palavras.%Apesar de não se quantificar a relação entre o uso de palavras no segundo corpus  sua classificação,  %A depender das conclusões retiradas, pode-se pensar em outras metodologias para a classificação dos documentos de acordo com suas perspectivas.

