\chapter{Conclusão}
\label{conclusoes}
%\section{Pontos fortes da metodologia proposta}


\section{Conclusões}
\label{freqs:conc}

%INTERNACIONALIZÁVEEEEEL!!

A classificação baseada em contagens de palavras, ou em alguma das variações mencionadas na introdução desse capítulo, assume a seguinte hipótese linguística: a quantidade de vezes que uma palavra é mencionada em um documento está diretamente relacionada a seu enfoque \cite{teubert}. Como consequência, esse método funciona melhor em \emph{datasets} nos quais o emprego de palavras varia significativamente por perspectiva. Esse parece ser o caso da maioria dos artigos estudados para este capítulo: cinco de seis trabalhos apresentaram uma boa taxa de acerto, considerando apenas contagens de palavras. Outros três trabalhos, apresentados no capítulo \ref{outros}, também fazem uso dessa informação - mas a associam a outras propriedades dos documentos classificados. De todo modo, a contagem de palavras mostrou ser a característica mais \textbf{essencial} à classificação por perspectiva, reforçando a ideia de que essa hipótese linguística é válida.


Nesse capítulo, foram revisados dois trabalhos que utilizam apenas essas contagens para classificar seus \emph{datasets} de estudo - eles são, inclusive, os mais citados dentre os treze analisados nessa monografia.

O primeiro, de Lin et al., apresenta um novo modelo para classificação (o LSPM), destacando-se dos demais artigos por não enfocar em SVMs ou Naïve Bayes. Diferentemente desses classificadores, o LSPM considera que apenas uma parte das sentenças de cada documento realmente apresenta um ponto de vista, e gera palavras mais específicas para cada uma delas. As demais frases concentram palavras mais genéricas, que poderiam ser empregadas da mesma forma por todos os lados do corpus. Por esse motivo, elas não contribuem diretamente com a classificação. O modelo apresenta uma boa taxa de acerto, mas não é tão estudado - nem tão trivial de implementar - quanto um Naïve Bayes. O trabalho é muito citado por ser um dos primeiros a tentar classificar documentos de acordo com suas perspectivas, e o \emph{dataset} analisado (artigos pró-Israel e pró-Palestina) também foi estudado por outros pesquisadores\footnote{Verificar \textbf{ANEXO BLA}.}.

O segundo, de Mullen e Malouf, é muito citado por ser um dos poucos que trabalha com um \emph{dataset} tão informal (\emph{posts} em um fórum sobre política), apresentando discussões interessantes sobre as dificuldades envolvidas no processo de classificá-lo. As taxas de acerto obtidas na classificação foram baixas, e um dos motivos possíveis, de acordo com o exposto no trabalho, é a quantidade de citações a textos escritos sob uma perspectiva diferente daquela que o autor defende. Isso \emph{mistura} contagens relativas a perspectivas distintas em um mesmo documento, homogeneizando-os sob o ponto de vista do classificador. 

O artigo de Lin et al. também apresentou uma boa taxa de acerto utilizando um Naïve Bayes, diferentemente do estudo de Mullen e Malouf. Apesar do corpus analisado por esses últimos ser pequeno, os autores indicam que a forma como cada perspectiva se apropria das palavras interfere na qualidade da classificação.  A fim de ampliar a compreensão sobre essa interferência, foram conduzidos dois experimentos envolvendo um Naïve Bayes e um L-LDA, aplicados a \emph{datasets} para os quais a classificação funcionou de forma diferente. O primeiro corpus considerado foi aquele estudado por Lin et Al., para o qual as taxas de acerto obtidas com um Naïve Bayes foram altas; o segundo, dado que não foi possível ter acesso aos documentos analisados por Mullen e Malouf, foi um conjunto de trechos de discursos em debates da \emph{House of Representatives}, órgão legislativo dos Estados Unidos. A taxa de acerto obtida com um Naïve Bayes nesse último corpus foi bastante baixa, tornando-o ideal para o objetivo dos experimentos. 

Nos experimentos com o L-LDA, cada documento foi associado a dois tópicos: um genérico e outro correspondente à sua perspectiva. Mesmo sabendo que em um Naïve Bayes não há distinção entre palavras genéricas e específicas, optou-se por essa divisão de tópicos por conta do objetivo da aplicação do L-LDA: a visualização parcial de que termos são mais enfocados por cada perspectiva. Essa informação sugere que há uma certa homogeneização nos enfoques do segundo \emph{dataset}, quando comparado com o primeiro. Considerando que quão mais homogêneo é o emprego de palavras por perspectiva, pior é o desempenho dos classificadores baseados em contagens de palavras, a informação obtida com o L-LDA ajuda a compreender porque a taxa de acerto obtida para o segundo \emph{dataset} foi tão mais baixa que aquelas obtidas para o primeiro. É importante frisar que não se encontrou \textbf{nenhum outro trabalho} que faça uso de um L-LDA para compreender, ainda que parcialmente, como certos termos são enfocados por diferentes perspectivas. Apesar de outros fatores contribuírem para o mau desempenho de uma classificação, como um número muito pequeno de documentos no \emph{dataset}, a investigação do emprego de palavras, quando as taxas de acerto obtidas não são boas, amplia a compreensão do corpus analisado - o que pode ser útil no momento de se pensar em outras estratégias para melhorar a classificação.  



\section{Dificuldades encontradas}

\section{Trabalhos futuros}

%\section{Divulgação}

%\section{Pontos fortes e fracos}

