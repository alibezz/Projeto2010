\chapter{Relação entre as características dos \emph{datasets} e as metodologias utilizadas}
\label{cap:caracsdatasets}

Os \emph{datasets} estudados nesse projeto são oriundos de fontes diversas, incluindo \emph{blogs} \cite{jiang-argamon} \cite{durant-smith}, matérias jornalísticas \cite{grefenstette-et-al} \cite{schimmelfing-baldwin}, artigos escritos por especialistas \cite{lin-et-al2006} \cite{efrom}, discussões \emph{online} \cite{somasundaran} \cite{wiebe08} e debates políticos \cite{hirst-et-al} \cite{thomas-pang-lee}. Os assuntos discutidos também são bastante variados, incluindo tópicos relativamente abstratos, como a discussão da pena de morte \cite{greeneTESE}, e outros mais objetivos, como possíveis \emph{designs} para um controle remoto \cite{somasundaranGRAPH} \cite{wiebe08}. As linguagens empregadas nos documentos diferem bastante de um trabalho para outro, variando tanto na informalidade dos termos e construções empregadas quanto no teor opinativo das colocações \textbf{sigo citando?}. Outra característica importante, que distingue um estudo de outro, envolve a língua - ou línguas - nas quais os documentos se encontram. \textbf{Ler um pouco sobre isso para amadurecer este ponto} Por fim, o tamanho dos textos analisados, que varia de algumas sentenças a vários parágrafos, bem como o nível de engajamento de seus autores com as perspectivas defendidas, indica uma Web muito plural no que diz respeito aos tipos de conteúdo \emph{online}. 

Nos trabalhos estudados para este projeto, percebeu-se que as características inerentes a cada \emph{dataset} pouco interferem na decisão dos métodos utilizados na mineração das perspectivas dos documentos. No decorrer deste capítulo, a forte relação que existe entre essas características e a escolha das metodologias será discutida, justificando parcialmente os resultados ruins encontrados em alguns artigos. Adicionalmente, através de experimentos em \emph{datasets} referenciados nesses estudos, ou coletados \emph{online}, este capítulo apontará possibilidades metodológicas que podem conduzir a melhorias nos resultados analisados. \textbf{Devo enfatizar a originalidade disso aqui? Acho q n, né? Fica na problematização.} O capítulo está estruturado da seguinte forma: \textbf{blablabla}. Por fim, na \textbf{Seção Y}, algumas combinações de características comuns em documentos da Web, como alto teor de linguagem opinativa em debates informais \emph{online} \cite{somasundaran}, serão analisadas conjuntamente.

\section{Palavras utilizadas nos documentos}

Uma hipótese apresentada em \cite{lin-et-al2006}, assumida por parte dos artigos estudados para este projeto, é de que a escolha de palavras em um documento reflete os pontos de vista e intenções de seu autor. O emprego de palavras semanticamente distintas para um mesmo propósito - como \emph{Revolução} ou \emph{Golpe} para o começo do Regime Militar Brasileiro em 1964 -, e também a frequência de seus usos, são elementos chave para a transmissão de posicionamentos diferentes sobre um determinado assunto. %Em \cite{lin-et-al2006}, por exemplo, foi observado que várias palavras, como \emph{palestinian} e \emph{israel}, são utilizadas tanto em documentos pró-Palestina quanto pró-Israel. Apesar disso, as frequências distintas no uso dessas palavras evidenciam os diferentes lados da discussão. 
Essa hipótese encontra respaldo em \cite{teubert2001}, um estudo de Linguística de Corpus \cite{biber-d1998}\cite{halliday2004} que indica que indivíduos defendendo perspectivas diferentes consolidam seus vocabulários através do uso de palavras específicas (\emph{stigma words} e \emph{banner words}), facilitando a identificação de adversários e aliados. 

A hipótese, entretanto, não é comprovada por todos os \emph{datasets} analisados. Em alguns deles, o conhecimento das palavras empregadas para cada perspectiva no \emph{dataset}, bem como suas frequências, não é suficiente para inferir o perfil ideológico dos autores dos documentos. \cite{agrawal2003} prevê este comportamento, defendendo que o vocabulário usado em dois lados de uma discussão tende a ser basicamente o mesmo, o que contribui para o mau desempenho de classificadores baseados em frequências de palavras exclusivamente. Esta ideia é explorada novamente em \cite{malouf-taking_sides}, a fim de justificar a taxa de acerto de apenas 63.59\% obtida na aplicação de um classificador Naïve Bayes padrão a um \emph{dataset} de debates políticos \emph{online} \cite{www-politics-org}.

Se um classificador utiliza apenas as palavras de um documento, bem como suas frequências, para identificar sua perspectiva, é natural que ele erre muito se essas características não mudam muito de uma perspectiva para outra. Apesar disso, verificar a relação existente entre a uniformidade das palavras e suas frequências e o desempenho desses classificadores não é trivial. A depender do \emph{dataset}, características como tamanho dos documentos e quantidade de palavras por documento contribuem de maneira mais decisiva para a taxa de acerto dos classificadores\footnote{A relação entre essas características e os métodos de classificação é discutida nas seções BLAAAAAA E BLIII dessa monografia.}. Por este motivo, uma análise prévia das palavras presentes no corpus, a fim de identificar quais delas se associam mais fortemente a cada uma das perspectivas e quais co-ocorrem em perspectivas diferentes, não necessariamente evidencia o bom ou o mau desempenho que um classificador desse tipo apresentará. 

Para comprovar essa hipótese, foram executados três experimentos com um modelo de tópicos do tipo L-LDA, \textbf{apresentado na seção XYZ dessa monografia}. Para cada experimento, todos os documentos envolvidos foram marcados com um rótulo referente à perspectiva e outro genérico, idêntico para todos eles. Essa estratégia facilitou a identificação de quais palavras melhor se associam a cada perspectiva e quais colaboram para uniformizar o vocabulário do corpus. Intuitivamente, uma pré-análise possível envolveria a simples contabilização, e posterior comparação, das frequências das palavras no \emph{dataset}, separadas por perspectiva. Essa metodologia, entretanto, não evidencia quais são as palavras que colaboram para a uniformização do corpus, algo que se obtém com o emprego de um tópico genérico em um L-LDA. Todos os experimentos utilizaram a implementação de L-LDA disponível em \cite{top-llda}. Para medir a performance de um classificador baseado em frequências de palavras, foi utilizada a implementação de Naïve Bayes disponível em \cite{alibezz-naive-bayes}. 

Para o primeiro experimento, foi utilizado o \emph{dataset} do artigo \cite{lin-et-al2006}, composto de artigos do \emph{site} bitterlemons.org escritos sob uma perspectiva pró-Palestina ou pró-Israel. Para o L-LDA, cada documento estava associado a dois tópicos: sua perspectiva (pró-Palestina ou pró-Israel) e um genérico, idêntico para todos eles. Esses artigos foram escritos ou pelos editores do \emph{site} ou por convidados, o que cria uma divisão natural corpus. Essa divisão foi utilizada em \cite{lin-et-al2006} para avaliar o desempenho de um Naïve Bayes: em um momento, os documentos de treino eram os escritos pelos editores e os de teste, aqueles escritos pelos convidados; em outro, tinha-se a situação inversa. Neste primeiro experimento, treinamos o Naïve Bayes com os documentos escritos pelos convidados e testamos o desempenho do classificador com os documentos escritos pelos editores. A situação inversa não precisou ser verificada para comprovar a hipótese desse experimento. É válido ressaltar que, em todos os experimentos, todas as palavras contidas nos documentos foram consideradas. Isto resultou em análises independentes de pré-processamentos comuns, como \emph{stemming}\footnote{escrever sobre isso em algum lugar} e retirada de \emph{stop words}\footnote{mesma coisa}.

\textbf{tabelas com palavras e desempenhos}

%Explicar a coisa das 100 palavras

No segundo experimento, foi utilizado um dos \emph{datasets} estudados em \cite{somasundaran}, composto de colocações em um debate sobre \emph{browsers} disponível no \emph{site} convinceme.net. A discussão divide-se em apenas dois lados: pró-Firefox e pró-Internet Explorer. Os documentos foram rotulados de forma análoga aos artigos do primeiro \emph{dataset} e o Naïve Bayes foi testado com uma \textbf{4-fold-cross-validation}. Este \emph{dataset} é pequeno, contendo apenas 959 palavras diferentes. %Mostrar a questão das palavras

%e associam mais fortemente  para cada perspectiva, bem como aquelas que co-ocorrem em lados distintos do corpus, uniformizando o vocabulário.
%Para mostrar que uma análise prévia do vocabulário do corpus não é suficiente para recomendar - ou desaconselhar - o uso de classificadores baseados em frequências de palavras, um experimento envolvendo um modelo de tópicos foi executado. Em vez de contar as frequências das palavras para cada perspectiva presente em um \emph{dataset}




 %disponível em \cite{top-llda} aplicada a três \emph{datasets}.\textbf{explicar a fonte do naive bayes, os resultados, o uso de stop words, as iterações.}% O primeiro, composto de artigos extraídos do site bitterlemons.org, foi classificado com um Naïve Bayes padrão no artigo \cite{lin-et-al2006}. As taxas de acerto obtidas, com o uso do Naïve Bayes, variaram entre 84.85\% e 93.46\% para os experimentos elencados nesse artigo. O segundo, \textbf{definir dataset, espero que o politics.com}, também foi classificado com um Naïve Bayes padrão em \cite{malouf-taking_sides} - mas as taxas de acerto foram bem mais baixas: \textbf{X\%}. Para o experimento com o L-LDA, todas as palavras contidas nos documentos, incluindo \emph{stop words} como \emph{the}, foram consideradas, resultando em uma análise das palavras independente do pré-processamento executado nos \emph{datasets} nos dois artigos citados.

%\textbf{Imagens, desempenhos.}

%\textbf{reafirme os resultados acima.} Diante disso, uma estratégia mais indicada é começar o processo de classificação do \emph{dataset} com um classificador baseado, inicialmente, apenas nas frequências das palavras do corpus. Se a taxa de acerto atingida for menor do que a desejada, explora-se outras características do \emph{dataset}. Nesta seção, serão descritas apenas as técnicas de classificação dos artigos que associaram, explicitamente, a uniformidade das palavras no corpus ao mau desempenho de classificadores desse tipo\footnote{Técnicas de classificação desenvolvidas em outros artigos serão apresentadas em outras seções.}.

Dos artigos estudados para este projeto, relacionados diretamente à Mineração de Perspectiva, 3 associaram o mau desempenho de classificadores baseados em palavras e suas frequências à homogeneização do vocabulário contido no corpus: \cite{malouf-taking_sides}, \cite{aaai-politics} e \cite{efron}. Não foi possível executar os experimentos descritos acima com o L-LDA em nenhum dos \emph{datasets} utilizados nesses trabalhos, pois eles não estão disponíveis na Web nem conseguiram ser obtidos mediante pedido, por \emph{e-mail}, aos autores dos artigos. Por este motivo, esta seção se limitará a descrever as técnicas utilizadas nesses trabalhos para melhorar as taxas de acerto na classificação dos corpora\footnote{Técnicas de classificação desenvolvidas por artigos que não tratam da questão da uniformidade das palavras serão apresentadas em outras seções desta monografia.}.

Em \cite{malouf-taking_sides} e \cite{aaai-politcs}, o \emph{dataset} estudado é o mesmo: um conjunto de debates políticos Estadunidenses extraídos do \emph{site} www.politics.com. Os dois trabalhos visavam a classificar os 185 participantes da discussão de acordo com suas orientações políticas: Esquerda ou Direita. Cada participante era representado por um único documento, resultante da concatenação de todos os seus \emph{posts} nos debates. Aplicando um Naïve Bayes na coleção de documentos, a taxa de acerto obtida em \cite{aaai-politics} foi de 60.37\%; em \cite{malouf-takind_sides}, 63.59\%. \cite{aaai-politcs} analisa o \emph{dataset} e conclui que 62.2\% dos \emph{posts} de Esquerda mencionam trechos de \emph{posts} de Direita. Quanto aos \emph{posts} de Direita, 77.5\% deles mencionam \emph{posts} de Esquerda. Essa forma de interação entre os \emph{posts} é explorada em \cite{malouf-taking_sides}. Os autores criam um grafo de co-citação em que cada vértice representa um usuário e cada citação de um \emph{post} a outro é indicada por uma aresta entre seus autores. A hipótese levantada é de que quão mais similares forem os padrões de citação de dois usuários, mais provavelmente eles defenderão uma mesma perspectiva política. Dada a matriz de adjacência desse grafo de co-citação, \textbf{M}, computa-se uma aproximação de baixo posto via Decomposição em Valores Singulares (SVD)\footnote{A técnica de aproximação para um posto menor via SVD tem que estar escrta em algum lugar!}, resultando na matriz \textbf{M'}. A aproximação da matriz por uma de posto menor via SVD é útil para extrair informações estruturais do grafo, como padrões de comunicação entre os vértices \cite{drineas}. Em seguida, calcula-se a distância entre os vértices em \textbf{M'} e agrupa-se os usuários de acordo com essa informação, através do algoritmo especificado em \cite{hoon}. Todos os \emph{posts} referentes a cada grupo obtido são concatenados, gerando uma coleção menor de documentos. Um classificador Naïve Bayes, também baseado em palavras e suas frequências, é aplicado a essa nova coleção e os resultados obtidos são propagados para todos os usuários associados a cada grupo. Para usuários com mais de 500 palavras nos debates, a taxa de acerto dessa metodologia de classificação é de 73\%.



\textbf{Grafozinho do Taking sides}

Padrões de citação entre documentos também foram investigados em \cite{efron}. Neste artigo, os experimentos envolvem 2 \emph{datasets}: o primeiro é composto de artigos políticos Estadunidenses de Direita ou Esquerda, coletados em \emph{sites} e \emph{blogs} políticos - explicitamente partidários ou não -; o segundo é composto de textos retirados de \emph{sites} sobre música, divididos entre as categorias \emph{Alternative} e \emph{Mainstream}. As aplicações de Naïve Bayes nestes corpora resultaram, respectivamente,\textbf{explicar melhor essa parte da coleta dos mainstream, q tá complexo.}
Sejam \textbf{L} e \textbf{R} duas listas de URLs associadas a pontos de vista opostos sobre um tópico \emph{T}. Para cada documento \emph{d\_i} do corpus, computa-se a probabilidade de \emph{d\_i} ser co-citado com algum elemento de \textbf{R} e, em seguida, com algum elemento de \textbf{L}. Se a razão entre estas probabilidades for maior que 1, o documento é classificado como portador da mesma perspectiva presente nas URLs de \textbf{R}. Caso esta razão seja menor que 1, a perspectiva associada ao documento será aquela relativa a \textbf{L}. Esta metodologia, aplicada ao primeiro \emph{dataset}, resulta em uma taxa de acerto de 94.1\%. No segundo \emph{dataset}, a taxa obtida é de até 88.84\%. Os resultados são muito bons, quando comparados com aqueles obtidos com Naïve Bayes e SVM, mas esta metodologia possui uma limitação importante: ela só é aplicável a \emph{datasets} contendo duas perspectivas, diferentemente, por exemplo, de um Naïve Bayes, facilmente adaptável a mais pontos de vista\footnote{Indicar algo para ler sobre multiclass text classif. com naive bayes}. Até mesmo o grafo de co-citação apresentado em \cite{malouf-taking_sides} não apresenta, de antemão, uma restrição ao número de perspectivas presentes no \emph{dataset}. 

\textbf{Concluir a seção.}
%o primeiro \emph{dataset}, os artigos estão escritos sob uma das seguintes perspectivas: pró-Palestina ou pró-Israel. Por conta disso, o tópico \emph{pal} foi atribuído a todos os documentos pró-Palestina e o tópico \emph{isr}, a todos os pró-Israel. Estes tópicos facilitam a visualização das palavras mais fortemente associadas a cada uma das duas perspectivas, de acordo com o vocabulário empregado nos artigos. Um terceiro tópico, \emph{gen}, foi atribuído a todos os documentos, a fim de capturar as palavras que co-ocorrem neles independentemente de suas perspectivas. Após a execução do modelo, as 100 palavras mais fortemente associadas a cada um dos 3 tópicos foram coletadas. 35\% das associadas a \emph{isr} não estão presentes no conjunto recolhido para \emph{gen}. Para \emph{pal}, essa percentagem cai para 29\%. Por fim, 32\% das palavras mais fortemente associadas a \emph{isr} não fazem parte das 100 palavras mais fortemente associadas a \emph{pal} e vice-versa. Essas percentagens indicam que os autores dos documentos pró-Israel utilizam um vocabulário ligeiramente mais específico, na defesa de seus pontos de vista, do que os autores pró-Palestina. É importante ressaltar que nenhuma palavra foi filtrada na análise - ou seja, termos muito frequentes como \emph{the}, \emph{of} e \emph{and}, comumente extraídos dos \emph{datasets} antes da etapa de classificação, estavam presentes nos documentos processados pelo L-LDA.    

%Palavras associadas a \emph{isr} que não foram associadas a \emph{gen}
%['arafat', 'be', 'some', 'roadmap', 'us', 'yet', 'out', 'sharon', 'ariel', 'support', 'three', 'bush', 'palestine', 'new', 'terrorism', 'leader', 'then', 'jewish', 'after', 'arab', 'leadership', 'plan', 'president', 'than', 'bank', 'prime', 'regarding', 'like', 'could', 'violence', 'against', 'while', 'time', 'american', 'first']

%Palavras associadas a \emph{pal} que não foram associadas a \emph{gen}
%['then', 'some', 'authority', 'against', 'occupied', 'negotiations', 'occupation', 'sharon', 'united', 'end', 'way', 'palestine', 'international', 'be', 'after', 'plan', 'president', 'law', 'those', 'prime', 'land', 'i', 'violence', 'us', 'q', 'while', 'time', 'situation', 'first']

%Palavras associadas a \emph{pal} que não foram associadas a \emph{isr}
%['because', 'people', 'authority', 'states', 'right', 'occupied', 'any', 'negotiations', 'occupation', 'what', 'united', 'end', 'also', 'been', 'their', 'other', 'way', 'international', 'law', 'do', 'which', 'government', 'very', 'they', 'now', 'those', 'about', 'land', 'these', 'q', 'i', 'situation']

%Palavras associadas a \emph{isr} que não foram associadas a \emph{pal}
%['arafat', 'into', 'settlements', 'years', 'yet', 'out', 'even', 'would', 'ariel', 'west', 'support', 'three', 'bush', 'gaza', 'new', 'terrorism', 'leader', 'we', 'jewish', 'arab', 'most', 'leadership', 'minister', 'roadmap', 'than', 'bank', 'both', 'regarding', 'like', 'could', 'war', 'american']
%\textbf{As palavras estão ordenadas de acordo com a força da associação com cada um dos tópicos}


%\textbf{Lista de palavras e desempenho. Imagens e tabelas.}

%Dado que em boa parte dos artigos estudados neste projeto, como \cite{lin-et-al2006} e \cite{klebanov}, atinge-se taxas de acerto superiores a 80\% com classificadores baseados em frequência de palavras, conclui-se que a mineração de perspectivas em discussões, artigos opinativos e debates requer metodologias diferentes, a depender de como as palavras foram escolhidas pelos autores dos documentos. %Nos debates estudados por \cite{hirst-et-al}, expressões de ataque e defesa são mais frequentes do que \emph{stigma words} e, como o método empregado no artigo foi um SVM treinado com frequências de palavras, observou-se que a classificação obtida para os lados do debate não refletia as perspectivas \emph{liberal} ou \emph{conservadora} - mas sim os lados \emph{oposição} (expressões de ataque) e \emph{situação} (expressões de defesa). 
%Estes estudos indicam a possibilidade de que, em debates e discussões nos quais há uma homogeneização do vocabulário empregado - o que pode acontecer quando todos os lados utilizam, em proporções similares, tanto expressões de ataque quanto de defesa -, classificadores baseados exclusivamente nas palavras utilizadas e/ou em suas frequências apresentarão má performance.

%A avaliação do desempenho desses classificadores\footnote{\textbf{SVMs e Naive Bayes padrão; LSPM}} nos \emph{datasets} estudados revela que artigos opinativos e notícias consolidaram perspectivas, através da escolha do vocabulário utilizado, melhor do que debates. Apesar disso, uma generalização neste sentido, restringindo o uso desses classificadores a artigos e notícias, não é recomendada por falta de indicativos linguísticos que comprovem essa tendência. Uma estratégia que pode ajudar na escolha ou descarte de um classificador desse tipo é uma análise das palavras que estão contidas nos documentos.

%\textbf{mostrar as percentagens prum dataset onde a linguagem eh mais uniforme. discutir.} 
%Explicar q isso nunca foi feito e q pessoas q ncontraram merda com essa feature fizeram outras coisas. descrever essas coisas.

%Estas hipóteses ilustram  
%Como indica \cite{}: 

%\textbf{MODO RASCUNHO AINDA}

%Explicar que uma diferença fundamental notada entre os datasets observados diz respeito à formalidade da linguagem empregada nos documentos. Enquanto alguns datasets utilizam documentos provenientes de meios onde a norma culta da linguagem impera, e uma revisão ortográfica é utilizada, outros são carregados de gírias, expressões e abreviações típicas da linguagem da Internet e contêm, eventualmente, grafias erradas para uma mesma palavra. <Dar exemplos textuais. Mostrar uma tabelinha, algo assim, indicando o volume de datasets com linguagem informal nos documentos estudados.> 

%A linguagem informal pode criar alguns desafios para a Mineração de Perspectiva [FECHAR O PROBLEMA EM: IDENTIFICAÇÃO DA PERSPECTIVA PRESENTE EM UM DOCUMENTO], especificamente no que diz respeito ao pré-processamento dos documentos e à escolha do método empregado. No pré-processamento, como indicado em (aaai-politics.pdf e 10.1.1.138.7160.pdf), a correção gramatical das palavras é bastante indicada. Com uma única versão de grafia para cada palavra (a correta), diminui-se a quantidade de ruído que grafias erradas podem causar na classificação.

%Uma característica dos datasets que deveria ser considerada sempre antes de se escolher o método utilizado - mas não é prática entre as pessoas que estudam perspective mining - é a frequência das palavras nos documentos do dataset. Se o léxico empregado pelos autores dos textos muda sensivelmente a depender de sua ideologia/perspectiva defendida/ponto de vista, é possível resolver o problema utilizando classificadores que usam essa frequencia como feature. GASTE TEMPO DANDO ALGUNS EXEMPLOS.  Em datasets informais, entretanto, como aponta Efron, a linguagem empregada por todos os lados da discussão pode ser basicamente a mesma: termos com forte carga de polaridade e gírias/jargões comuns na discussão [EXEMPLO]. Neste caso, é preciso utilizar métodos que utilizem mecanismos mais rebuscados do que a simples frequência/presença das palavras no texto. Alguns autores utilizam métodos mais gramaticais para lidar com datasets informais, como é o caso de , BLE e BLI. Os 2 primeiros criam o conceito de Opinion Frame (DEFINIR O CONCEITO). No primeiro caso, a ideia é associar corretamente opiniões a alvos, e associar alvos iguais utilizando técnicas de co-referência. Segundo Wiebe et al. (pegar a citação corretamente), ter as targets associadas, com as opiniões próximas, é uma boa forma de entender o overall de opiniões de um documento. A estratégia é uma alternativa possível para documentos em que as perspectivas estão muito associadas à linguagem opinativa, e onde essa linguagem é comum para todos os lados. Infelizmente, os resultados alcançados indicam que a tarefa não é trivial: blablablablababla (resolver coreferencia pra linkar targets não é tão simples assim => e dê exemplo). 

%uma diferença fundamental notada entre os \emph{datasets} observados diz respeito à formalidade da linguagem empregada nos documentos. Enquanto alguns datasets utilizam documentos provenientes de meios onde a norma culta da linguagem impera, e uma revisão ortográfica é utilizada, outros são carregados de gírias, expressões e abreviações típicas da linguagem da Internet e contêm, eventualmente, grafias erradas para uma mesma palavra. <Dar exemplos textuais. Mostrar uma tabelinha, algo assim, indicando o volume de datasets com linguagem informal nos documentos estudados.> 

