Alexandre: oi
  talvez eu tenha que interromper a reunião no meio
  pra descer pro ciclo básico pra passar uma prova pros alunos do meu orientador, ok?
 eu: ok
 Alexandre: mas lá terei internet, acredito
09:03 eu: sem problemas
  podemos começar?
 Alexandre: ok
 eu: entonces
09:04 essa semana eu li poucos artigos
  2 apenas
  mas estudei algumas coutras coisas
  e acabei tendo algumas ideias
 Alexandre: certo
  primeiro os artigos?
 eu: ok
  o primeiro artigo que li
  (xô abrir minhas anotações)
09:05 chama-se "Recognizing Stances in Online Debates"
  e usa um método unsupervised
  basicamente, a coisa funciona assim
09:06 existe um dicionário de adjetivos marcados com polaridade gigantão para língua inglesa
  o método consiste em extrair todos esses adjetivos de cada lado do debate
09:07 e, através do Stanfor Parser e umas regrinhas, montar tuplas com possíveis targets
  aqui umas regrinhas:
  1 - Direct Object rule: the target is the direct object of the opinion dobj(opinion, target) => I love (opinion1) Firefox (target1)

2 - Nominal Subject rule: The target is the subjective of the opinion nsubj(opinion, target) => IE(target1) breaks(opinion) with everything.

etc etc (Table 1 do artigo)
  isso eh uma grande source of errors
  e ela explica isso no artigo, inclusive
09:08 na montagem das tuplas, ela troca o adjetivo per se pela sua polaridade
  tomando o cuidado de ver se ele tah numa oração adversativa ou precedido de 'não' (nesses casos, ela nega a polaridade)
  ela troca o adjetivo pela polaridade pra q a informação n fique mto esparsa
09:09 aí ela faz assim
  filtra quais desses polarity-target pairs vão ser mesmo usados
  ela busca todos q tem a ver com os topicos principais
  no caso do dataset q tou montaando, seria algo como Serra e Dilma
09:10 e, para cada um q aparece, busca todos os outros q tão na vizinhança
  ela estabelece a vizinhança como 5 sentenças depois
  e a mesma sentença
  depois, ela calcula Probabilidade da target Y ter recebido uma opinião negativa na vizinhança duma opinião positiva pra X.
09:11 oq eh tudo facinho de fazer qdo vc recupera os dados
  com isso pronto, e os analogos disso
  ela cria um scoring
  wj = P(topic1+|target_i_p) + P(topic2-|target_i_p) (side1)
uj = P(topic1-|target_i_p) + P(topic2+|target_i_p) (side2)
  e aí vai prum problema de maximizar
09:12 o somatorio de wjxj + ujyj
  um minuto
 Alexandre: ij
  ok
09:13 eu: onde xj e yj pertencem a {0,1}, xj + yj = 1, xj - xj
  ignore oq vai depois da virgula
  ela cria uns baselines
  pra comparar
09:14 scoring só pras polarity-targets referentes aos topicos principais
  e chega a resultados mto bons
09:15 ela discute q as source of errors são imensas
  desde o dicionário até o mais punk de todos, q eh montar as tuplas
  e como o fato de n usar co-reference faz ela perder polarity-targets q seriam uteis
09:16 xô dar um exemplo dos resultados q ela chega
09:17 considerando só os topicos fundamentais, em um debate de Firefox vs. IE (62 posts), ela atinge accuracy de 33.87, Recall de 33.87, F1 de 45.16
  com a vizinhança, vai respectivamente pra 66.13, 66.13, 66.13
09:18 ou seja, mesmo havendo mto ruido, o ganho de vc considerar a vizinhança é hiper significativo pra definir lados em debates
  eu achei bacana, por ser unsupervised
  e atingir um nivel legal ainda assim
  eu acredito apenas q, se há uma etapa aih pra ser melhorada,
09:19 eh essa de montar as tuplas
 Alexandre: ele mede o que nesses valores exatamente?
 eu: ela mede a classificação dos posts
 Alexandre: classificação em lados?
 eu: sim
09:20 se é pro-firefox
 Alexandre: assim
  isso parece péssimo
 eu: ou pró-ie
 Alexandre: se a accuracy é 30% é pior que aleatório
 eu: pois eh
 Alexandre: e 66% ainda é bem ruim
09:21 eu: e os exemplos todos, só com os topicos, ficaram mto ruins
  ainda eh bem ruim? mesmo sendo totalmente unsupervised?
 Alexandre: sim
  ainda é perto do aleatório
 eu: é, ainda é
09:22 mas eu acho q pruma coisa tão ás cegas assim, n eh trivial subir isso tant
 Alexandre: não é completamente às cegas
  se ela usa um léxicon de polaridade
 eu: é verdade
  mas ela n retira as ambiguidades desse lexicon
09:23 mas de fato
  isso eh informação de fora
  eu acredito q o problema aih estah na forma de montar os target-polarity pairs
 Alexandre: pois é
  que é meio esquisito
 eu: essas regrinhas do stanford parser tão loooonge de ser suficientes
09:24 vc faria como para melhorar isso, de forma n supervisionada?
 Alexandre: existem jeitos melhores de detectar referências
09:25 http://aclweb.org/anthology-new/D/D09/D09-1120.pdf
  por exemplo, o tipo de regra que esse artigo usa pra achar referência e referente
 eu: vou ler
09:26 Alexandre: outra coisa que vc pode fazer é usar um modelo parecido com tópicos pra escolher os dois conjuntos de texto que minimizam a similaridade das palavras seed, ou então o conjunto que maximiza a similaridade de uma seed com coisas positivas e a outra com coisas negativas e coisas assim
 eu: hummmm
09:27 isso eu n pensaria
  bom, o outro artigo
 Alexandre: diga
 eu: chama-se
  Coupling Niche Browsers and Affect Analysis for an Opinion Mining Application
  e eh de 2004
09:28 então ainda eh meio naïf em algumas coisas
  ele usa datasets de noticia para avaliar como é q pessoas públicas estão sendo 'quistas'
  teoricamente, notícias n são tão opinionadas
09:29 mas ele mostra com os resultados dele aquilo q todo mundo sabe, né?
  a midia eh parcial, sim
  no tratamento q dá às pessoas
  ele vai no news.google.com
  chupa os 1000 posts mais recentes sobre uma pessoa publica
  ou chupa tudo q acha entre duas datas estabelecida
09:30 usa um programa chamado KWIC
  q eh de 78!!!
  pra extrair 120 caracteres antes e depois do nome da coisa buscada
  (passo mto desnecessario, na moral)
  ordena e retira duplicatas
09:31 e retira todas as affect words
  usando um dicionário de palavras-polaridade
  só.
 Alexandre: ah
 eu: aí ele cria um escore
 Alexandre: é que kwic é uma coisa meio famosa
  pro povo de antigamente
 eu: de dividir palavras positivas por negativas encontradas
  pois eh, eh famoso msm. mas pq n tratat a zorra do texto inteiro?
09:32 Alexandre: tem justificativas pra isso
  o que é esquisito é pegar 120 caracteres
  e não um número de palavras
 eu: ele disse q pretende variar as janelas
 Alexandre: o resto do texto não se espera que esteja tão correlacionado com a palavra central que o contexto em que ela ocorre
  isso é útil em vários métodos
 eu: pois eh
09:33 ele n explica mto bem, mas de fato faz sentido. vc pode eliminar ruidos aih, especialmente pq n faz nada do tipo achar targets pros adjetivos
  então, fechando uma janela, infere-se q tudo ali se refere ao termo central
  oq n eh tao absurdo assim
09:34 bom, daí ele divide a qtd de coisas positivas pela de coisas negativas encontradas nas noticias
  quão mais acima de 1
  melhor a pessoa tah sendo falada
  quão mais abaixo de 1, pior
  ele mostra como schwarznegger eh falado enqto o tempo passa
  em um jornal da calfornia
09:35 eh algo simples pra caramba
  n considera negações dos adjetivos pra mudar polaridade
  nada assim
  mas acaba sendo eficiente
 Alexandre: ah, legal
  eu gosto desse tipo de coisa
  e a abordagem é simples mas não é boba
  aline
  vou descer aqui pro lugar da prova
 eu: ok
 Alexandre: se eu não voltar em 15min é porque estou frustrado com o treco da internet
09:36 ok?
 eu: ok
  tou em casa, anyway
  =)
09:37 uma coisa q ele podia usar pra melhorar eh co-referencia
  daih, ele abria janelinhas
  tb pros 'He, it' da vida
09:38 mas de fato, agora ficou claro pra mim como eh bom usar essa janela, se vc n quer ficar catando target
  deixei aqui escrito pra vc ler qdo chegar
 Alexandre: ok
  agora vou de fato
  beijos
 eu: inté
  beijos
	19 minutos
09:58 Alexandre: oi
  desculpa a demora
  o pidgin surtou
  mas o gmail foi
 eu: =)
  bom
  foi otimo falar com vc
  e atentar pra issso das janelas
09:59 ó
  a ideia q tive
 Alexandre: diga
 eu: foi aproveitar o LDA
  pra tentar ajudar
  a entender essa coisa das eleições no brasil
  infelizmente, n achei NENHUM sentiment detector
  pra lingu portuguesa free
 Alexandre: normal
  agora, assim
10:00 eu: mas achei POS taggers, q ajudam a pelo menos saber se uma palavra eh ou n um adjetivo
 Alexandre: essas coisas não funcionam trivialmente pra qualquer corpus
  e tem métodos que com corpora minimamente anotados vc consegue usar
 eu: eu achei um artigo
  q tou pra ler aqui
 Alexandre: qual?
10:01 eu: Predicting the Semantic Orientation of Adjectives
  a mulher parte da ideia de q adjetivos parecidos em polaridade andam juntps
  e parece q, com seeds pequenas inicialmente
  consegue agrupar bolos enormes de adjetivos
  ou seja, só com um pos-tagger e esse troço dela, parece q dá pra se aproximar de um sentiment analyser
  n sei ainda, tem q ver
10:02 mas a ideia é: um modelo de topicos agrupa trends, certo?
  ou seja, vc vai ter bolos de substantivos e adjetivos juntos
  ver a inclinação desses adjetivos
  mesmo q os substantivos n sejam seus targets
 Alexandre: veja o artigo do google
10:03 viability of web derived polarity lexicons
  no google scholar vc acha
 eu: vou catar
 Alexandre: é o mais recente nessa área de propagação de grafos
  e o métdo é facilmente traduzível
 eu: mas tipo: ninguem usa lda pra ajudar em opinion mining, n?
  tipo, as pessoas estao aih
  fazendo absurdos
  pra achar targets
  em cima de opinioes
10:04 eu acho q isso eh bocó. vc n precisa ser tao strict e querer achar a target exata
  um modelo mais smooth separe por topicos pode ajudar mto
 Alexandre: eu não sei de LDA pra sentiment; é uma possível área de pesquisa, acho
 eu: eu animei de fazer um experimento com isso, simplesmente pq n me parece absurdo
  eu fiquei pensando em pq seria absurdo
 Alexandre: acho válido tentar
10:05 eu: mas, no maximo, eh impreciso.
 Alexandre: e ver no que quebra
 eu: vc concorda q eh mais natural doq ficar catando piolho em cabeça de target?
 Alexandre: de certa forma sim
 eu: pode ser q n funcione tao bem, mas tem menos source of errors
 Alexandre: mas não resolve o problema totalmente
 eu: sim, n
  aih podia fazer assim
 Alexandre: afinal
  lda no máximo vai achar um tópico pra cada target
10:06 e isso não é garantido
 eu: n, n eh
 Alexandre: mas provavelmente os topicos dos targets vão estar em todos os documentos
 eu: mas a ideia eh ver q adjetivos e substantivos andam juntos, saca?
 Alexandre: se lembre que lda é intrinsecamente bagh-of-words
  então não deve detectar isso de andar coladinho
  só de ir pro mesmo bar
 eu: sim
  mas ó
10:07 modelos bag of words
  como naive bayes
  e lspm (reza a lenda do artigo) funcionam bem
 Alexandre: porque, se entendi direito, o que esse treco faz pra achar target que vc reclama
  é pra achar que palavras modificam gramaticamente o target
  e a partir da polaridade delas tentar determinar a polaridade do texto
  correto?
 eu: depende do artigo
10:08 tem aquele q queria gerar uma tupla enorme, lembra?
 Alexandre: sim
 eu: e depois queria inka-las por target
 Alexandre: isso é co-referência
  na verdade
  se eu fosse sugerir
  um avanço pra isso
  seria resolver coreferência global primeiro
  depois olhar algumas adjetivações óbvias sobre as coisas que se referem aos targets
10:09 e tentar separar a polaridade a partir disso
  com, no máximo, talvez, depois, uma etapa de bootstrap, pra determinar que PT = dilma = mercadante = operário, etc
 eu: umhum
 Alexandre: mas até sem isso
  vc já deve conseguir separar razoavelmente bem as coisas mais óbvias
10:10 eu: vamos tentar fechar uma ideia então?
  rodar o lda
 Alexandre: calma
  antes de rodar o lda
10:11 eu quero que vc me diga o que vc espera encontrar lá
  e por que, por exemplo, um hard clustering não é melhor que lda pra essa aplicação
  ou uma mistura dos dois
 eu: n conheço hard clustering =/
 Alexandre: hard clustering é clustering
  tipo
  dirichlet-multinomial, clustering via naive bayes
 eu: por contagem, simplesmente?
10:12 Alexandre: não
  clustering com aquele modelo de naive bayes não supervisionado
  em que documentos pertencem a 1 cluster
 eu: ah, sim
 Alexandre: e não tem pedaços de todos
10:13 eu: bom, como eu penso em rodar a coisa pra documentos alinhados ideologicamente (ou seja, rodar duas vezes), n há necessidade dum documento pertencer a mais de uma classificação ideologica. maaaaas eu acho q eh legal ver se há topicos dentro de cada um dos dois corpora
  e se os adjetivos vao mudando de cara
  a depender do topico
 Alexandre: é isso
 eu: se isso faz algum sentido
 Alexandre: vc pode usar um topic model misturado com um clustering desses
  tipo
10:14 cada cluster tem alguns tópicos específicos e alguns tópicos compartilhados
  e ver qual a cara que eles ficam
 eu: dá mto trabalho fazer isso? n, né?
 Alexandre: não
  é exatamente o mesmo modelo que eu estava usando pra opinion mining
 eu: eu queria aproveitar ao maximo as coisas q jah tenho feitas
 Alexandre: com menos resampling das opiniões
10:15 eu: vc pode me explicar aqui ou por email mais claramente como eh isso? tipo: onde entra o lda e o naive bayes (se eh q eles entram)?
10:16 Alexandre: bom
  antes
  me diga qual o seu cenário
  tipo
  quais os dados que vc tem
  o que vc sabe sobre eles
  e o que vc quer saber
  e aí clarifica o que está na minha cabeça
 eu: ok
  bom
  eu em breve terei varios posts de blogs de revista q descem o cacete em dilma
10:17 ou em serra
  pq falar bem mesmo, eles n falam
 Alexandre: certo
  e vc vai saber quais são quais, ou quer descobrir quais são quais?
 eu: eu sei quais são quais
  eu quero investigar
  a gradação
  dos adjetivos
 Alexandre: certo
 eu: a gradação das criticas
 Alexandre: vc quer um modelo só com adjetivos
 eu: em relaçao a topicos
  e substantivos
 Alexandre: ou gradação das críticas em geral?
10:18 eu: eu queria pegar um bolo de criticas a dilma e ver assim: ela tá sendo mais criticada qdo tais e tais palavras ocorrem
  daí buscar essas palavraas nos posts
 Alexandre: certo
 eu: e tentar ver se faz sentido, se eh um fato, uma época
 Alexandre: vc pode então tentar um modelo com 3 tópicos
  um comum só aos artigos que criticam a dilma
  um comum só aos que criticam o serra
 eu: eh diferente de classificar, saca? pra classificar, devo experimentar o naive bayes turbinado.
10:19 Alexandre: certo
  e um de background
  e aí vc pode rodar um topic model
  com esses topicos fixos sobre os artigos
  e ver o que acha
  claro
  vc pode também colocar K topicos só dilma M só serra e N genéricos
  pra ver se pega gradações mais finas
10:20 eu: rodar o tpic model misturando os q descem o cacete em dilma e em serra ou rodar uma vez de cada, para quem desce o cacete em dilma e quem desce em serra?
  essas gradações mais finas me interessam mais
 Alexandre: rodar um topico geral
 eu: entendi. dá pra fazer as duas coisas
 Alexandre: que vai te dizer também quais são as críticas comuns
10:21 eu: agora como determino de antemão q eh um pra dilma, um pra serra e um de background?
  eh rezar pro lda separar assim, certo?
 Alexandre: hã?
  vc escolhe quantos vc quer pra cada tipo de coisa
  depende da granularidade
10:22 e do número de artigos que vc tem
 eu: essa parte tá confusa pra mim... tipo, até hj, nunca escolhi qtos topicos queria pra cada tipo de coisa. apenas escolhia qtos topicos eu queria, sabe?
 Alexandre: coloque a princípio 5 pra cada
  sim, line
  só que
  eu estou dizendo
  escolha 15 tópicos
  (por exemplo)
  5 deles só existem nos textos que falam da dilma
  e 5 só existem nos que falam do serra
10:23 os outros existem em todos
 eu: entendi.
 Alexandre: aí vc roda um LDA normal
  e vê o que acontece
  quer dizer
  não exatamente normal
  mas só modificado pra respeitar essas constraints
10:24 é o semi-supervised lda que eu tenho código lá
 eu: oq eu n captei ainda é o seguinte: eu escolho esses topicos, que são palavras nos corpora, e essa informação n se embute no lda, certo? ela vai ser apenas utilizada depois, pra fazer a análise.
  aaaaaaa
  agora entendi
 Alexandre: entendeu o que?
 eu: eh o semi-supervised lda
  por isso dah pra jogar topicos nele
 Alexandre: hm
  mais ou menos
  pense assim
  é um topic model
10:25 em que vc sabe quais topicos podem estar em cada documento
  mas não o que tem dentro desses tópicos
  e o modelo descobre o que tem dentro pra vc
 eu: issso
 Alexandre: e também o que cada um representa
 eu: mas eu digo os topicos
  ;)
 Alexandre: vc não diz os tópicos completamente
  o modelo te diz o que eles são
  vc só diz onde eles podem estar
 eu: sim, eu soh dou a palavra-chave
  atraves da qual o modelo cria o conceito
  alimentando de relaçoes
 Alexandre: não
10:26 vc nem dá palavra-chave nenhuma
  vc só marca os documentos
  dizendo que tópicos eles podem ter
  e vê o que acontece
 eu: entendi
 Alexandre: leia labeled lda
 eu: marco os de dilma com os 5 dela e os 5 de background
  os de serra com os 5 dele e os 5 de background
 Alexandre: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.155.3678&rep=rep1&type=pdf
 eu: massa
  vou ler agora
10:27 Alexandre: (essa é a vantagem de alguém ter publicado o treco antes de mim, eu não preciso explicar tudo :-) )
 eu: :-)
  tou pensando em topicos pra usar
  acho q preciso ler um pouco das noticias
10:28 a palavra dilma aparece mais nos anti-dilma
  doq nos pró-dilma
  e vice-versa pra serra
  foi oq disse. eles descem o cacete, mas n falam bem. seria puxa-saquismo demais,
  nunca li nada
  sobre esse tipo de experimento
  q vamos fazer
 Alexandre: é
10:29 é interesante
 eu: qto mais em português
 Alexandre: agora olhe pra o resultado desse topic model como um começo, e não um fim
  depois vamos pensar em como refinar isso
 eu: entendo
10:30 Alexandre: pra ter uma análise melhor, ou pra usar pra classificação, ou pra ver, a partir desse seed set, como o resto da mídia se comporta (vendo as proporções desses tópicos em outros artigos, etc)
 eu: pra me ajudar a selecionar os tópicos, vc me sugere alguma coisa computacional?
  tipo, contagem, sei lá
 Alexandre: como assim selecionar os tópicos?
 eu: marcar os documentos
 Alexandre: aline
 eu: aaaaa
 Alexandre: vc marca assim
 eu: entendi
10:31 Alexandre: if dilma: tem esses
 eu: n uso palavra alguma
 Alexandre: else: tem esses outros
  só
  deixa o lda calcular as palavras
  que melhor se encaixam com essa distribuição dos tópicos que vc fez
  leia o artigo do labeled lda
 eu: 'esses' e 'esses outros' n são palavras. bom, vou ler o artigo pra n faalar mais merda.
 Alexandre: e pense em serra e dilma como tags
 eu: umhum
10:32 acho q está bom por hj, né? :-)
  vc tem criticas a fazer?
  acha q tah tudo indo conforme deveria, etc etc?
 Alexandre: sim, sim
 eu: acho q tou lendo menos doq deveria
 Alexandre: leia o artigo do labeled lda
  talvez
10:33 2 ou 3 artigos por semana não é nada
  e leia o artigo do haghighi sobre coreferência
 eu: semana passada eu li bem mais
 Alexandre: pra entender que existem melhores features pra determinar o que está falando de uma mention
 eu: sim, lerei esses
10:34 e outros mais da area de opinion mining
  inté, top!
  beijos
 Alexandre: até
