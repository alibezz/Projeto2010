Essa versão do LSPM não está usando um dos termos da equação original para amostrar documentos, que é justamente a prob. duma frase ser relevante ser da classe. Está sendo admitido que essa prob. é 0.5.

23/05
Hoje, depois de fazer um parser pro corpus anotado de sentenças do bitterlemons, vou rodar prum pedacinho do corpus e ver se ele saca a diferença dos documentos. Pra isso, é claro, vou manter uma lista do que é Palestina e do que é Jerusalém. Quem viver, verá. :-)
Decisões de projeto: arrumar esse parser pra documentos reais antes de dizer se o modelo tá certo ou n; com aqueles documentos gerados artificialmente pelo parse_docs.py, tava mta forçação de barra! A idéia é fazer cru e, depois, botar iterações iniciais pra descartar e só aproveitar a computação de tempos em tempos (tudo bem que pareeece que tá convergindo rápido). Depois, o mais importante é fechar uma partezinha do corpus pra deixar semi-supervisionado.

Bom, mudança de planos: fazer um script que separe o nome dos autores e se é palestina ou israel, marcando os documentos numa tabela em algum lugar. Com isso feito, rodar com o máximo de documentos que o programa consiga pegar em tempo de um dia de execução.

MIL MUDANÇAS IMPORTANTES!

Agora, vou usar o corpus que efetivamente foi utilizado no artigo do LSPM, em vez daquilo que baixei do site na tora: http://sites.google.com/site/weihaolinatcmu/data

Isso é crucial para saber que estamos comparando de igual pra igual, nosso modelo com o deles (como assim n pensei nisso antes, Brasil?).

Outra coisa: na hora de escolher os documentos, n eh pra escolhê-los aleatoriamente. É melhor escolher os autores aleatoriamente. P q isso?

ah, e uma dica
se vc for rodar seu experimento, e vc tem acesso a informação de autores, o ideal não é vc escolher textos aleatórios pra fazer treinamento e teste e sim escolher autores aleatórios pra treinamento e teste
aí vc tem certeza que está identificando perspectivas mesmo e não só fazendo identificação de autores

24/05

Rodar a parada com 40% dos autores. Importante monitorar o numero de iterações. Vou começar com 1000 e jogar tudo num arquivo (?).

Autores escolhidos para primeiro teste:

['Manuel Hassassian', 'Zahira Kamal', 'Qadura Fares', 'Lamis Andoni', 'Majid Al-Haj', 'Tamar Hermann', 'Yossi Alpher', 'Maha Abu Dayyeh Shamas', 'Danny Ayalon', 'Yaron Ezrahi', 'Salem Ajluni', 'Uri Savir', 'Arnon Soffer', 'Yossi Melman', 'Saleh Abdul Jawad', 'Michael Tarazi', 'Dan Meridor', 'Ephraim Sneh', 'Shimon Peres', "Meir Pa'il", 'Reuven Merhav', 'Zeev Schiff', 'Jonathan Kuttab', 'Michael Eitan', 'Uri Ariel', 'Amira Hass', 'Galia Golan', 'Arie Lova Eliav', 'Hasan Asfour', 'Rami Shehadeh', 'Smadar Perry', 'Saeb Erekat', 'Bishop Munib Younan', 'Noah Kinarty', 'Yair Sheleg', 'Bruce Maddy-Weitzman', 'Ephraim Inbar', 'Dov Sedaka', 'Sari Hanafi', 'Efraim Inbar', 'Danny Rothschild', 'Ziad Abu Zayyad', 'Nabeel Kassis', 'Bassam Al-Salhi', 'Nabil Khatib', 'Intisar al Wazir', 'Meron Benvenisti', 'Mouin Rabbani', 'Shlomo Brom', 'Moriah Shlomot', 'George Giacaman', 'Sami Awad', 'Amnon Lord', 'Ingrid Gassner Jaradat', 'Ahmad Harb', 'Arnon Groiss', 'Samih Al Abed', 'Zakaria Al Agha', 'Yaacov Amidror', 'Dror Etkes', 'Ghassan Andoni', 'Ihsan Asalim', 'Amir Cheshin', 'Saul Singer', 'Menachem Froman', 'Amireh Hanna', 'Alon Liel', 'Shlomo Ben-Ami', 'Danny Rubinstein', 'Sam Bahour', 'Muhsin Yusuf', 'Nadia Naser-Najjab', 'Uri Elitzur', 'Yaser M. Dajani', 'Yossi Sarid', 'Bassam Salahi', 'Abraham Ben-Zvi', 'Meir Sheetrit', 'Hatem Abdel Qader', 'Dan Schueftan']
 
